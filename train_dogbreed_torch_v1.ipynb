{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: https://www.kaggle.com/c/dog-breed-identification/data\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import os, sys\n",
    "import argparse\n",
    "import json\n",
    "import numpy as np\n",
    "import pprint\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "\n",
    "from configs.config_train import get_cfg_defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(**args):\n",
    "    parser = argparse.ArgumentParser(description='dog breed')\n",
    "    parser.add_argument(\"--cfg\", type=str, default=\"configs/config_train.yaml\", help=\"Configurations.\")\n",
    "    # return parser.parse_args(**args)          # for python\n",
    "    return parser.parse_known_args(**args)    # for jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path:  D:\\GitWork\\dog_breed\\data\n",
      "\n",
      "Columns:  ['id', 'breed']\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10222 entries, 0 to 10221\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      10222 non-null  object\n",
      " 1   breed   10222 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 159.8+ KB\n",
      "None\n",
      "\n",
      "                                 id             breed\n",
      "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
      "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
      "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
      "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
      "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever\n"
     ]
    }
   ],
   "source": [
    "data_path = r'D:\\GitWork\\dog_breed\\data'\n",
    "print('Data path: ', data_path)\n",
    "\n",
    "label_path = r'D:\\GitWork\\dog_breed\\data\\raw'\n",
    "label_fname = 'labels.csv'\n",
    "\n",
    "lbl_abspath = os.path.join(label_path, label_fname)\n",
    "df = pd.read_csv(lbl_abspath)\n",
    "\n",
    "columns = list(df.columns)\n",
    "print('\\nColumns: ', columns)\n",
    "print()\n",
    "\n",
    "print(df.info());print()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num id series:  10222\n",
      "\n",
      "Num for train:  8177\n",
      "Num for valid:  2045\n",
      "\n",
      "Train ids:\n",
      "000bec180eb18c7604dcecc8fe0dba07\n",
      "001513dfcb2ffafc82cccf4d8bbaba97\n",
      "001cdf01b096e06d78e9e5112d419397\n",
      "00214f311d5d2247d5dfe4fe24b2303d\n",
      "0021f9ceb3235effd7fcde7f7538ed62\n",
      "002211c81b498ef88e1b40b9abf84e1d\n",
      "00290d3e1fdd27226ba27a8ce248ce85\n",
      "002a283a315af96eaea0e28e7163b21b\n",
      "003df8b8a8b05244b1d920bb6cf451f9\n",
      "0042188c895a2f14ef64a918ed9c7b64\n",
      "\n",
      "Train files:\n",
      "D:\\GitWork\\dog_breed\\data\\train\\000bec180eb18c7604dcecc8fe0dba07.jpg\n",
      "D:\\GitWork\\dog_breed\\data\\train\\001513dfcb2ffafc82cccf4d8bbaba97.jpg\n",
      "D:\\GitWork\\dog_breed\\data\\train\\001cdf01b096e06d78e9e5112d419397.jpg\n",
      "D:\\GitWork\\dog_breed\\data\\train\\00214f311d5d2247d5dfe4fe24b2303d.jpg\n",
      "D:\\GitWork\\dog_breed\\data\\train\\0021f9ceb3235effd7fcde7f7538ed62.jpg\n",
      "D:\\GitWork\\dog_breed\\data\\train\\002211c81b498ef88e1b40b9abf84e1d.jpg\n",
      "D:\\GitWork\\dog_breed\\data\\train\\00290d3e1fdd27226ba27a8ce248ce85.jpg\n",
      "D:\\GitWork\\dog_breed\\data\\train\\002a283a315af96eaea0e28e7163b21b.jpg\n",
      "D:\\GitWork\\dog_breed\\data\\train\\003df8b8a8b05244b1d920bb6cf451f9.jpg\n",
      "D:\\GitWork\\dog_breed\\data\\train\\0042188c895a2f14ef64a918ed9c7b64.jpg\n",
      "\n",
      "Valid files:\n",
      "D:\\GitWork\\dog_breed\\data\\train\\cc93915e06bc55626a02af95006a48c2.jpg\n",
      "D:\\GitWork\\dog_breed\\data\\train\\cc964d3bf1e317c9fbb0c0d4c8bc6b8f.jpg\n",
      "D:\\GitWork\\dog_breed\\data\\train\\cc97041986abdb8566a3ed4317f40c27.jpg\n",
      "D:\\GitWork\\dog_breed\\data\\train\\cc99de39a169a9aebaf34d4a514e266b.jpg\n",
      "D:\\GitWork\\dog_breed\\data\\train\\cc9b4190a7063f8e92dd21ff25152643.jpg\n",
      "D:\\GitWork\\dog_breed\\data\\train\\cca773094173965bbd04f829eea6eec7.jpg\n",
      "D:\\GitWork\\dog_breed\\data\\train\\ccb296c8257649527e45affde75d331d.jpg\n",
      "D:\\GitWork\\dog_breed\\data\\train\\ccb75b5d00281575fe98f1d56d23d7a9.jpg\n",
      "D:\\GitWork\\dog_breed\\data\\train\\ccbf2d7da8e85a3b60eb0ff8a87af58f.jpg\n",
      "D:\\GitWork\\dog_breed\\data\\train\\ccc369e93d792e44329a5f13ae6ae582.jpg\n"
     ]
    }
   ],
   "source": [
    "# Create train ids and valid ids\n",
    "\n",
    "frac_for_train = 0.8\n",
    "\n",
    "id_sers = Series.to_numpy(df[\"id\"])\n",
    "id_sers_num = id_sers.shape[0]\n",
    "print('Num id series: ', id_sers_num)\n",
    "\n",
    "train_num = int(float(id_sers_num) * float(frac_for_train))\n",
    "valid_num = id_sers_num - train_num\n",
    "print('\\nNum for train: ', train_num)\n",
    "print('Num for valid: ', valid_num)\n",
    "\n",
    "train_ids = id_sers[:train_num]\n",
    "valid_ids = id_sers[train_num:]\n",
    "print('\\nTrain ids:'); print('\\n'.join(train_ids[:10]))\n",
    "\n",
    "train_path = os.path.join(data_path, 'train')\n",
    "train_files = [os.path.join(train_path, f+'.jpg') for f in train_ids]\n",
    "valid_files = [os.path.join(train_path, f+'.jpg') for f in valid_ids]\n",
    "\n",
    "print('\\nTrain files:'); print('\\n'.join(train_files[:10]))\n",
    "print('\\nValid files:'); print('\\n'.join(valid_files[:10]))\n",
    "\n",
    "ProcPath = r'D:\\GitWork\\dog_breed\\data\\processed'\n",
    "np.save(os.path.join(ProcPath, \"train_ids.npy\"), train_files)\n",
    "np.save(os.path.join(ProcPath, \"valid_ids.npy\"), valid_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breed series num:  10222\n",
      "Breed set size:  120\n",
      "\n",
      "Breed dict len:  120\n",
      "{\n",
      "    \"affenpinscher\": 0,\n",
      "    \"afghan_hound\": 1,\n",
      "    \"african_hunting_dog\": 2,\n",
      "    \"airedale\": 3,\n",
      "    \"american_staffordshire_terrier\": 4,\n",
      "    \"appenzeller\": 5,\n",
      "    \"australian_terrier\": 6,\n",
      "    \"basenji\": 7,\n",
      "    \"basset\": 8,\n",
      "    \"beagle\": 9,\n",
      "    \"bedlington_terrier\": 10,\n",
      "    \"bernese_mountain_dog\": 11,\n",
      "    \"black-and-tan_coonhound\": 12,\n",
      "    \"blenheim_spaniel\": 13,\n",
      "    \"bloodhound\": 14,\n",
      "    \"bluetick\": 15,\n",
      "    \"border_collie\": 16,\n",
      "    \"border_terrier\": 17,\n",
      "    \"borzoi\": 18,\n",
      "    \"boston_bull\": 19,\n",
      "    \"bouvier_des_flandres\": 20,\n",
      "    \"boxer\": 21,\n",
      "    \"brabancon_griffon\": 22,\n",
      "    \"briard\": 23,\n",
      "    \"brittany_spaniel\": 24,\n",
      "    \"bull_mastiff\": 25,\n",
      "    \"cairn\": 26,\n",
      "    \"cardigan\": 27,\n",
      "    \"chesapeake_bay_retriever\": 28,\n",
      "    \"chihuahua\": 29,\n",
      "    \"chow\": 30,\n",
      "    \"clumber\": 31,\n",
      "    \"cocker_spaniel\": 32,\n",
      "    \"collie\": 33,\n",
      "    \"curly-coated_retriever\": 34,\n",
      "    \"dandie_dinmont\": 35,\n",
      "    \"dhole\": 36,\n",
      "    \"dingo\": 37,\n",
      "    \"doberman\": 38,\n",
      "    \"english_foxhound\": 39,\n",
      "    \"english_setter\": 40,\n",
      "    \"english_springer\": 41,\n",
      "    \"entlebucher\": 42,\n",
      "    \"eskimo_dog\": 43,\n",
      "    \"flat-coated_retriever\": 44,\n",
      "    \"french_bulldog\": 45,\n",
      "    \"german_shepherd\": 46,\n",
      "    \"german_short-haired_pointer\": 47,\n",
      "    \"giant_schnauzer\": 48,\n",
      "    \"golden_retriever\": 49,\n",
      "    \"gordon_setter\": 50,\n",
      "    \"great_dane\": 51,\n",
      "    \"great_pyrenees\": 52,\n",
      "    \"greater_swiss_mountain_dog\": 53,\n",
      "    \"groenendael\": 54,\n",
      "    \"ibizan_hound\": 55,\n",
      "    \"irish_setter\": 56,\n",
      "    \"irish_terrier\": 57,\n",
      "    \"irish_water_spaniel\": 58,\n",
      "    \"irish_wolfhound\": 59,\n",
      "    \"italian_greyhound\": 60,\n",
      "    \"japanese_spaniel\": 61,\n",
      "    \"keeshond\": 62,\n",
      "    \"kelpie\": 63,\n",
      "    \"kerry_blue_terrier\": 64,\n",
      "    \"komondor\": 65,\n",
      "    \"kuvasz\": 66,\n",
      "    \"labrador_retriever\": 67,\n",
      "    \"lakeland_terrier\": 68,\n",
      "    \"leonberg\": 69,\n",
      "    \"lhasa\": 70,\n",
      "    \"malamute\": 71,\n",
      "    \"malinois\": 72,\n",
      "    \"maltese_dog\": 73,\n",
      "    \"mexican_hairless\": 74,\n",
      "    \"miniature_pinscher\": 75,\n",
      "    \"miniature_poodle\": 76,\n",
      "    \"miniature_schnauzer\": 77,\n",
      "    \"newfoundland\": 78,\n",
      "    \"norfolk_terrier\": 79,\n",
      "    \"norwegian_elkhound\": 80,\n",
      "    \"norwich_terrier\": 81,\n",
      "    \"old_english_sheepdog\": 82,\n",
      "    \"otterhound\": 83,\n",
      "    \"papillon\": 84,\n",
      "    \"pekinese\": 85,\n",
      "    \"pembroke\": 86,\n",
      "    \"pomeranian\": 87,\n",
      "    \"pug\": 88,\n",
      "    \"redbone\": 89,\n",
      "    \"rhodesian_ridgeback\": 90,\n",
      "    \"rottweiler\": 91,\n",
      "    \"saint_bernard\": 92,\n",
      "    \"saluki\": 93,\n",
      "    \"samoyed\": 94,\n",
      "    \"schipperke\": 95,\n",
      "    \"scotch_terrier\": 96,\n",
      "    \"scottish_deerhound\": 97,\n",
      "    \"sealyham_terrier\": 98,\n",
      "    \"shetland_sheepdog\": 99,\n",
      "    \"shih-tzu\": 100,\n",
      "    \"siberian_husky\": 101,\n",
      "    \"silky_terrier\": 102,\n",
      "    \"soft-coated_wheaten_terrier\": 103,\n",
      "    \"staffordshire_bullterrier\": 104,\n",
      "    \"standard_poodle\": 105,\n",
      "    \"standard_schnauzer\": 106,\n",
      "    \"sussex_spaniel\": 107,\n",
      "    \"tibetan_mastiff\": 108,\n",
      "    \"tibetan_terrier\": 109,\n",
      "    \"toy_poodle\": 110,\n",
      "    \"toy_terrier\": 111,\n",
      "    \"vizsla\": 112,\n",
      "    \"walker_hound\": 113,\n",
      "    \"weimaraner\": 114,\n",
      "    \"welsh_springer_spaniel\": 115,\n",
      "    \"west_highland_white_terrier\": 116,\n",
      "    \"whippet\": 117,\n",
      "    \"wire-haired_fox_terrier\": 118,\n",
      "    \"yorkshire_terrier\": 119\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 建立品種名稱與編號的對應字典\n",
    "\n",
    "breed_sers = Series.to_numpy(df['breed'])\n",
    "breed_sers_num = breed_sers.shape[0]\n",
    "print('Breed series num: ', breed_sers_num)\n",
    "    \n",
    "# 整理有多少種品種\n",
    "breed_set = set(breed_sers)\n",
    "breed_set_len = len(breed_set)\n",
    "print('Breed set size: ', breed_set_len)\n",
    "\n",
    "# 建構一個品種名稱與編號的對應字典\n",
    "breed_list = list(breed_set)\n",
    "breed_list.sort()\n",
    "breed_dict = { v:i for i, v in enumerate(breed_list) }\n",
    "breed_dict_len = len(breed_dict)\n",
    "\n",
    "print('\\nBreed dict len: ', breed_dict_len)\n",
    "print(json.dumps(breed_dict, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,breed,breed_id\n",
      "000bec180eb18c7604dcecc8fe0dba07, boston_bull       , 19\n",
      "001513dfcb2ffafc82cccf4d8bbaba97, dingo             , 37\n",
      "001cdf01b096e06d78e9e5112d419397, pekinese          , 85\n",
      "00214f311d5d2247d5dfe4fe24b2303d, bluetick          , 15\n",
      "0021f9ceb3235effd7fcde7f7538ed62, golden_retriever  , 49\n",
      "002211c81b498ef88e1b40b9abf84e1d, bedlington_terrier, 10\n",
      "00290d3e1fdd27226ba27a8ce248ce85, bedlington_terrier, 10\n",
      "002a283a315af96eaea0e28e7163b21b, borzoi            , 18\n",
      "003df8b8a8b05244b1d920bb6cf451f9, basenji           , 7\n",
      "0042188c895a2f14ef64a918ed9c7b64, scottish_deerhound, 97\n",
      "\n",
      "[19, 37, 85, 15, 49, 10, 10, 18, 7, 97]\n"
     ]
    }
   ],
   "source": [
    "# 將 label.csv 中所有的品種類別轉換成品種編號\n",
    "\n",
    "train_bids = [breed_dict[df.loc[df['id']==i].breed.item()] for i in train_ids]\n",
    "valid_bids = [breed_dict[df.loc[df['id']==i].breed.item()] for i in valid_ids]\n",
    "\n",
    "def showBreedIds(ids, num=10):\n",
    "    sample = ids[:num]\n",
    "    breeds = [df.loc[df['id']==i].breed.item() for i in sample]\n",
    "    bids = [breed_dict[i] for i in breeds]\n",
    "    \n",
    "    col_width = max(len(i) for i in breeds)\n",
    "    print('id,breed,breed_id')\n",
    "    for i in range(len(sample)):\n",
    "        v = sample[i]\n",
    "        breed = \"\".join(breeds[i].ljust(col_width))\n",
    "        print('{}, {}, {}'.format(v, breed, bids[i]))\n",
    "    return\n",
    "        \n",
    "showBreedIds(train_ids, num=10)\n",
    "print(); print(train_bids[:10])\n",
    "\n",
    "# print()\n",
    "# showBreedIds(valid_ids, num=10)\n",
    "# print(); print(valid_bids[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save labels as file\n",
    "np.save(os.path.join(ProcPath, \"train_labels.npy\"), train_bids)\n",
    "np.save(os.path.join(ProcPath, \"valid_labels.npy\"), valid_bids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-bb2d70553866>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[0mtrainSet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmyDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mProcPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[0mtrainLoader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainLoader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Create Dataset\n",
    "\n",
    "# Normalize\n",
    "normalize = transforms.Normalize(\n",
    "    mean = [0.485, 0.456, 0.406],\n",
    "    std  = [0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "\n",
    "def default_loader(imgPath, fname):\n",
    "    img_pil = Image.open(os.path.join(imgPath, fname))\n",
    "    img_pil = img_pil.resize((224,224))\n",
    "    return img_pil\n",
    "\n",
    "\n",
    "class myDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, path, phase='train', transform=None):\n",
    "        img_files = os.path.join(path, '{}_ids.npy'.format(phase))\n",
    "        lbl_files = os.path.join(path, '{}_labels.npy'.format(phase))\n",
    "        \n",
    "        self.images = np.load(img_files)\n",
    "        self.labels = np.load(lbl_files)\n",
    "        self.transform = transform\n",
    "        self.len = len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_file = self.images[index]\n",
    "        \n",
    "        img = Image.open(img_file)\n",
    "        img = img.resize((224,224))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        lbl = self.labels[index]\n",
    "        return img, lbl\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "trainSet = myDataset(ProcPath, transform=transform)\n",
    "trainLoader = DataLoader(trainSet, batch_size=100, shuffle=True)\n",
    "print(trainLoader.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, txt, transform=None, target_transform=None, loader=default_loader):\n",
    "        fh = open(txt, 'r')\n",
    "        imgs = []\n",
    "        for line in fh:\n",
    "            line = line.strip('\\n')\n",
    "            line = line.rstrip()\n",
    "            words = line.split()\n",
    "            imgs.append((words[0],int(words[1])))\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fn, label = self.imgs[index]\n",
    "        img = self.loader(fn)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "train_data=MyDataset(txt='mnist_test.txt', transform=transforms.ToTensor())\n",
    "data_loader = DataLoader(train_data, batch_size=100,shuffle=True)\n",
    "print(len(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "normalize = transforms.Normalize(\n",
    "    mean = [0.485, 0.456, 0.406],\n",
    "    std  = [0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "# Transform\n",
    "train_transform = transforms.Compose([\n",
    "#     transforms.Scale(256),\n",
    "#     transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data  = trainset()\n",
    "train_loader = DataLoader(train_data, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "torch.Size([4, 3, 224, 224]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "print(type(train_loader))\n",
    "\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = data_iter.next()\n",
    "\n",
    "print(type(images), type(labels))\n",
    "print(images.size(), labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # arguments \n",
    "    args, _ = parse_args()\n",
    "    print(args)\n",
    "\n",
    "    cfg = get_cfg_defaults()\n",
    "    cfg.merge_from_file(args.cfg)\n",
    "    cfg.freeze()\n",
    "    print(cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
