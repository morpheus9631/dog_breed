{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: https://www.kaggle.com/c/dog-breed-identification/data\n",
    "# Author: Morpheus Hsieh\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "# import os, sys\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw path: 'D:\\GitWork\\dog_breed\\data\\raw'\n",
      "Processed path: 'D:\\GitWork\\dog_breed\\data\\processed'\n"
     ]
    }
   ],
   "source": [
    "RawPath = r'D:\\GitWork\\dog_breed\\data\\raw'\n",
    "print(\"Raw path: '{}'\".format(RawPath))\n",
    "\n",
    "ProcPath = r'D:\\GitWork\\dog_breed\\data\\processed'\n",
    "print(\"Processed path: '{}'\".format(ProcPath))\n",
    "\n",
    "fname_breeds_dict = 'breeds_dict.csv'\n",
    "fname_labels_proc = 'labels_processed.csv'\n",
    "\n",
    "BatchSize = 16\n",
    "NUM_BREED_CLASSES = 16\n",
    "FRAC_FOR_TRAIN = 0.8\n",
    "\n",
    "Phase = ['train', 'valid']\n",
    "\n",
    "npz_files = {\n",
    "    'train': 'train_data.npz',\n",
    "    'valid': 'valid_data.npz'\n",
    "}\n",
    "\n",
    "npz_columns = ['images', 'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load most popular 16 breeds and breed ids\n",
    "csv_breeds = join(ProcPath, fname_breeds_dict)\n",
    "df_breeds = pd.read_csv(csv_breeds)\n",
    "print(df_breeds.info());\n",
    "print(df_breeds.head())\n",
    "\n",
    "selected_breed_list = list(df_breedict['breed'][:NUM_BREED_CLASSES] )\n",
    "print(); print(selected_breed_list)\n",
    "\n",
    "# Create breed dict\n",
    "breed_data = df_labels[df_labels['breed'].isin(selected_breed_list)]\n",
    "\n",
    "\n",
    "\n",
    "# import json\n",
    "\n",
    "# # Load breed dictionary from csv file\n",
    "# def getBreedDict(path, fname):\n",
    "#     csv_abspath = join(ProcPath, breed_dict_fname)\n",
    "#     df = pd.read_csv(csv_abspath)\n",
    "#     dic = {}\n",
    "#     for i, (b, bid) in df.iterrows():\n",
    "#         dic[bid] = b\n",
    "#     return dic    \n",
    "    \n",
    "# breed_dict_fname = 'breed_dict.csv'\n",
    "# breed_dict_bw = getBreedDict(ProcPath, breed_dict_fname)\n",
    "# print(json.dumps(breed_dict_bw, indent=4))\n",
    "# # print(breed_dict_bw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120 entries, 0 to 119\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   breed     120 non-null    object\n",
      " 1   count     120 non-null    int64 \n",
      " 2   breed_id  120 non-null    int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 2.9+ KB\n",
      "None\n",
      "                  breed  count  breed_id\n",
      "0    scottish_deerhound    126         1\n",
      "1           maltese_dog    117         2\n",
      "2          afghan_hound    116         3\n",
      "3           entlebucher    115         4\n",
      "4  bernese_mountain_dog    114         5\n",
      "\n",
      "['scottish_deerhound', 'maltese_dog', 'afghan_hound', 'entlebucher', 'bernese_mountain_dog', 'shih-tzu', 'great_pyrenees', 'pomeranian', 'basenji', 'samoyed', 'airedale', 'tibetan_terrier', 'leonberg', 'cairn', 'beagle', 'japanese_spaniel']\n",
      "                                     id               breed  breed_id  \\\n",
      "8      003df8b8a8b05244b1d920bb6cf451f9             basenji         9   \n",
      "9      0042188c895a2f14ef64a918ed9c7b64  scottish_deerhound         1   \n",
      "12     00693b8bc2470375cc744a6391d397ec         maltese_dog         2   \n",
      "29     00bee065dcec471f26394855c5c2f3de               cairn        14   \n",
      "48     013f8fdf6d638c7bb042f5f17e8a9fdc     tibetan_terrier        12   \n",
      "...                                 ...                 ...       ...   \n",
      "10207  ffa4e1bf959425bad9228b04af40ac76             basenji         9   \n",
      "10212  ffc532991d3cd7880d27a449ed1c4770     tibetan_terrier        12   \n",
      "10215  ffcde16e7da0872c357fbc7e2168c05f            airedale        11   \n",
      "10216  ffcffab7e4beef9a9b8076ef2ca51909             samoyed        10   \n",
      "10219  ffe2ca6c940cddfee68fa3cc6c63213f            airedale        11   \n",
      "\n",
      "                                                   image  \n",
      "8      D:\\GitWork\\dog_breed\\data\\raw\\train\\003df8b8a8...  \n",
      "9      D:\\GitWork\\dog_breed\\data\\raw\\train\\0042188c89...  \n",
      "12     D:\\GitWork\\dog_breed\\data\\raw\\train\\00693b8bc2...  \n",
      "29     D:\\GitWork\\dog_breed\\data\\raw\\train\\00bee065dc...  \n",
      "48     D:\\GitWork\\dog_breed\\data\\raw\\train\\013f8fdf6d...  \n",
      "...                                                  ...  \n",
      "10207  D:\\GitWork\\dog_breed\\data\\raw\\train\\ffa4e1bf95...  \n",
      "10212  D:\\GitWork\\dog_breed\\data\\raw\\train\\ffc532991d...  \n",
      "10215  D:\\GitWork\\dog_breed\\data\\raw\\train\\ffcde16e7d...  \n",
      "10216  D:\\GitWork\\dog_breed\\data\\raw\\train\\ffcffab7e4...  \n",
      "10219  D:\\GitWork\\dog_breed\\data\\raw\\train\\ffe2ca6c94...  \n",
      "\n",
      "[1777 rows x 4 columns]\n",
      "\n",
      "Total rows: 1777\n",
      "Train len : 1421\n",
      "Valid len : 356\n"
     ]
    }
   ],
   "source": [
    "# Filter labels data accoring to selected breeds\n",
    "csv_labels = join(ProcPath, fname_labels_proc)\n",
    "df_labels  = pd.read_csv(csv_labels)\n",
    "train_data = df_labels[df_labels['breed'].isin(selected_breed_list)]\n",
    "print(train_data)\n",
    "\n",
    "img_list = list(train_data['image'])\n",
    "lbl_list = list(train_data['breed_id'])\n",
    "\n",
    "data_rows = len(train_data)\n",
    "print('\\nTotal rows:', data_rows)\n",
    "\n",
    "train_len = int(float(FRAC_FOR_TRAIN) * float(data_rows))\n",
    "print('Train len :', train_len)\n",
    "print('Valid len :', data_rows - train_len)\n",
    "\n",
    "train_imgs = img_list[:train_len]\n",
    "train_lbls = lbl_list[:train_len]\n",
    "\n",
    "valid_imgs = img_list[train_len:]\n",
    "valid_lbls = lbl_list[train_len:]\n",
    "\n",
    "data = [\n",
    "    [train_imgs, train_lbls],\n",
    "    [valid_imgs, valid_lbls]\n",
    "]\n",
    "\n",
    "# Save data as npz file\n",
    "for i in range(len(Phase)):\n",
    "    args = { npz_columns[0]: data[i][0], npz_columns[1]: data[i][1] }\n",
    "    fname = npz_files[Phase[i]]\n",
    "    out_fname = join(ProcPath, fname)\n",
    "    np.savez(out_fname, **args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.npz\n",
      "valid_data.npz\n",
      "\n",
      "TrainSet size:  1421\n",
      "ValidSet size:  356\n",
      "\n",
      "TrainLoader size:  89\n",
      "ValidLoader size:  23\n",
      "\n",
      "Image type:  <class 'torch.Tensor'>\n",
      "      size:  torch.Size([16, 3, 224, 224])\n",
      "\n",
      "Label type:  <class 'torch.Tensor'>\n",
      "      size:  torch.Size([16])\n",
      "\n",
      "Image:  torch.Size([3, 224, 224])\n",
      "\n",
      "tensor([[[ 0.0741,  0.0741,  0.0741,  ..., -1.8610, -1.8610, -1.8439],\n",
      "         [ 0.0741,  0.0741,  0.0741,  ..., -1.9124, -1.9124, -1.9295],\n",
      "         [ 0.0741,  0.0741,  0.0741,  ..., -1.9124, -1.9124, -1.9124],\n",
      "         ...,\n",
      "         [-0.3712, -0.3027, -0.3027,  ...,  0.0056, -0.0287, -0.0287],\n",
      "         [-0.2171, -0.2513, -0.2342,  ...,  0.0398,  0.0398,  0.0398],\n",
      "         [ 0.0227, -0.0116,  0.0227,  ..., -0.0972, -0.0801, -0.0116]],\n",
      "\n",
      "        [[ 0.2227,  0.2227,  0.2227,  ..., -1.7731, -1.7731, -1.7556],\n",
      "         [ 0.2227,  0.2227,  0.2227,  ..., -1.8256, -1.8256, -1.8431],\n",
      "         [ 0.2227,  0.2227,  0.2227,  ..., -1.8256, -1.8256, -1.8256],\n",
      "         ...,\n",
      "         [-0.5126, -0.4426, -0.4426,  ..., -0.1275, -0.1625, -0.1625],\n",
      "         [-0.3550, -0.3725, -0.3550,  ..., -0.0924, -0.0924, -0.0924],\n",
      "         [-0.1099, -0.1450, -0.0924,  ..., -0.2325, -0.2150, -0.1450]],\n",
      "\n",
      "        [[ 0.1999,  0.1999,  0.1999,  ..., -1.5779, -1.5779, -1.5604],\n",
      "         [ 0.1999,  0.1999,  0.1999,  ..., -1.6302, -1.6302, -1.6476],\n",
      "         [ 0.1999,  0.1999,  0.1999,  ..., -1.6302, -1.6302, -1.6302],\n",
      "         ...,\n",
      "         [-0.7936, -0.7238, -0.7238,  ..., -0.4101, -0.4450, -0.4450],\n",
      "         [-0.6890, -0.7238, -0.7238,  ..., -0.3753, -0.3753, -0.3753],\n",
      "         [-0.4624, -0.5147, -0.4798,  ..., -0.5147, -0.4973, -0.4275]]])\n",
      "\n",
      "Label:  tensor([ 6.,  1., 14., 13.,  2.,  4., 11.,  4., 13.,  5.,  4., 15.,  5., 12.,\n",
      "         3.,  5.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "normalize = transforms.Normalize(\n",
    "    mean = [0.485, 0.456, 0.406],\n",
    "    std  = [0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "class myDataset(Dataset):\n",
    "    \n",
    "    npzFiles = { \n",
    "        'train': 'train_data.npz', \n",
    "        'valid': 'valid_data.npz' \n",
    "    }\n",
    "\n",
    "    def __init__(self, path, phase='train', transform=None):\n",
    "        npz_fname = self.npzFiles[phase]\n",
    "        print(npz_fname)\n",
    "        \n",
    "        data = np.load(join(path, npz_fname), allow_pickle=True)\n",
    "        self.images = data['images']\n",
    "        self.labels = data['labels']\n",
    "\n",
    "        self.transform = transform\n",
    "        self.len = len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.images[index]\n",
    "        img_pil = Image.open(img_path)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img_pil)\n",
    "\n",
    "        lbl = float(self.labels[index])\n",
    "        \n",
    "        return [img, lbl]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    \n",
    "trainSet = myDataset(ProcPath, transform=transform)\n",
    "validSet = myDataset(ProcPath, phase='valid', transform=transform)\n",
    "print('\\nTrainSet size: ', len(trainSet))\n",
    "print('ValidSet size: ', len(validSet))\n",
    "\n",
    "trainLoader = DataLoader(trainSet, batch_size=BatchSize, shuffle=True)\n",
    "validLoader = DataLoader(validSet, batch_size=BatchSize, shuffle=False)\n",
    "print('\\nTrainLoader size: ', len(trainLoader))\n",
    "print('ValidLoader size: ', len(validLoader))\n",
    "\n",
    "trainSize = len(trainSet)\n",
    "validSize = len(validSet)\n",
    "\n",
    "imgs, lbls = next(iter(trainLoader))\n",
    "print('\\nImage type: ', type(imgs))\n",
    "print('      size: ', imgs.size())\n",
    "\n",
    "print('\\nLabel type: ', type(lbls))\n",
    "print('      size: ', lbls.size())\n",
    "\n",
    "img = imgs[0]\n",
    "print('\\nImage: ', img.shape)\n",
    "print(); print(img)\n",
    "\n",
    "print('\\nLabel: ', lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image size: torch.Size([6, 3, 224, 224])\n",
      "label size: torch.Size([6])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'breed_dict_bw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-2d16b95e14b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# Make a grid from batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbreed_dict_bw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlbls\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-33-2d16b95e14b3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# Make a grid from batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbreed_dict_bw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlbls\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'breed_dict_bw' is not defined"
     ]
    }
   ],
   "source": [
    "# Imshow for Tensor\n",
    "def imshow(inp, title=None):\n",
    "    inp  = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std  = np.array([0.229, 0.224, 0.225])\n",
    "    inp  = std * inp + mean\n",
    "    plt.figure(figsize=(16, 4))\n",
    "    plt.imshow(inp)\n",
    "    \n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    return\n",
    "\n",
    "sampleLoader = DataLoader(trainSet, batch_size=6, shuffle=True)    \n",
    "\n",
    "# Get a batch of training data\n",
    "imgs, lbls = next(iter(sampleLoader))\n",
    "print('image size: {}'.format(imgs.size()))\n",
    "print('label size: {}'.format(lbls.size()))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(imgs)\n",
    "imshow(out, title=[breed_dict_bw.get(x.item()) for x in lbls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "inputs, labels = next(iter(trainLoader))\n",
    "if use_gpu:\n",
    "    resnet = resnet.cuda()\n",
    "    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())   \n",
    "else:\n",
    "    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "outputs = resnet(inputs)\n",
    "outputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataloders, model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "    dataset_sizes = {'train': len(dataloders['train'].dataset), \n",
    "                     'valid': len(dataloders['valid'].dataset)}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloders[phase]:\n",
    "                if use_gpu:\n",
    "                    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(True):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs.data, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.data[0]\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            scheduler.step()\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                train_epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "            else:\n",
    "                valid_epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                valid_epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "                \n",
    "            if phase == 'valid' and valid_epoch_acc > best_acc:\n",
    "                best_acc = valid_epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "        print('Epoch [{}/{}] train loss: {:.4f} acc: {:.4f} ' \n",
    "              'valid loss: {:.4f} acc: {:.4f}'.format(\n",
    "                epoch, num_epochs - 1,\n",
    "                train_epoch_loss, train_epoch_acc, \n",
    "                valid_epoch_loss, valid_epoch_acc))\n",
    "            \n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet50(pretrained=True)\n",
    "\n",
    "# freeze all model parameters\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# new final layer with 16 classes\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(num_ftrs, 16)\n",
    "if use_gpu:\n",
    "    resnet = resnet.cuda()\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "dataLoaders = { 'train':trainLoader, 'valid':validLoader }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model = train_model(dataLoaders, resnet, criterion, optimizer, exp_lr_scheduler, num_epochs=2)\n",
    "print('Training time: {:10f} minutes'.format((time.time()-start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(dataloders, model, num_images=16):\n",
    "    cnt = 0\n",
    "    fig = plt.figure(1, figsize=(16, 16))\n",
    "    grid = ImageGrid(fig, 111, nrows_ncols=(4, 4), axes_pad=0.05)\n",
    "    for i, (inputs, labels) in enumerate(dataloders['valid']):\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "        for j in range(inputs.size()[0]):\n",
    "            ax = grid[cnt]\n",
    "            imshow(ax, inputs.cpu().data[j])\n",
    "            ax.text(10, 210, '{}/{}'.format(preds[j], labels.data[j]), \n",
    "                    color='k', backgroundcolor='w', alpha=0.8)\n",
    "            cnt += 1\n",
    "            if cnt == num_images:\n",
    "                return\n",
    "            \n",
    "visualize_model(dloaders, resnet)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
