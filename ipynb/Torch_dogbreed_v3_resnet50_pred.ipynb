{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.5.1\n",
      "Torchvision Version:  0.6.1\n"
     ]
    }
   ],
   "source": [
    "# From: https://www.kaggle.com/c/dog-breed-identification/data\n",
    "# Author: Morpheus Hsieh\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import os, sys\n",
    "import copy\n",
    "import io\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from os import listdir\n",
    "from os.path import join, isfile, split\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "{\n",
      "    \"DataPath\": \"D:\\\\GitWork\\\\dog_breed\\\\data\",\n",
      "    \"OutPath\": \"D:\\\\GitWork\\\\dog_breed\\\\output\",\n",
      "    \"ProcPath\": \"D:\\\\GitWork\\\\dog_breed\\\\processed\",\n",
      "    \"PreTrainPath\": \"D:\\\\GitWork\\\\dog_breed\\\\pretrained\",\n",
      "    \"PreTrainFile\": \"resnet50_20200925-1555_acc80.pth\",\n",
      "    \"LoadPreModel\": false,\n",
      "    \"TestPath\": \"D:\\\\Dataset\\\\dog-breed-identification\\\\test\",\n",
      "    \"TrainPath\": \"D:\\\\Dataset\\\\dog-breed-identification\\\\train\",\n",
      "    \"CsvLabel\": \"labels.csv\",\n",
      "    \"BatchSize\": 16,\n",
      "    \"FracForTrain\": 0.8\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load parameters from json file\n",
    "\n",
    "OutPath = r'D:\\GitWork\\dog_breed\\output'\n",
    "\n",
    "cfgPath = r'D:\\GitWork\\dog_breed\\configs'\n",
    "fname = 'Params_20200923-2230.json'\n",
    "json_file = join(cfgPath, fname)\n",
    "\n",
    "with open(json_file) as fin: \n",
    "    Params = json.load(fin) \n",
    "\n",
    "print('Parameters:')\n",
    "print(json.dumps(Params, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10222 entries, 0 to 10221\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      10222 non-null  object\n",
      " 1   breed   10222 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 159.8+ KB\n",
      "None\n",
      "\n",
      "                                 id             breed\n",
      "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
      "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
      "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
      "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
      "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever\n",
      "\n",
      "Num classes: 10222\n"
     ]
    }
   ],
   "source": [
    "# Read labels information\n",
    "\n",
    "DataPath = Params.get('DataPath')\n",
    "csv_labels = Params.get('CsvLabel')\n",
    "f_abspath = join(DataPath, csv_labels)\n",
    "\n",
    "df_labels = pd.read_csv(f_abspath)\n",
    "\n",
    "print(df_labels.info())\n",
    "print(); print(df_labels.head())\n",
    "\n",
    "NumClasses = df_labels.shape[0]\n",
    "print('\\nNum classes:', NumClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120 entries, 0 to 119\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   breed_id  120 non-null    int64 \n",
      " 1   breed     120 non-null    object\n",
      " 2   count     120 non-null    int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 2.9+ KB\n",
      "None\n",
      "\n",
      "   breed_id                 breed  count\n",
      "0         0    scottish_deerhound    126\n",
      "1         1           maltese_dog    117\n",
      "2         2          afghan_hound    116\n",
      "3         3           entlebucher    115\n",
      "4         4  bernese_mountain_dog    114\n",
      "\n",
      "Num classes: 120\n",
      "\n",
      "Breeds dict backward:\n",
      "{\n",
      "  0: scottish_deerhound\n",
      "  1: maltese_dog\n",
      "  2: afghan_hound\n",
      "  3: entlebucher\n",
      "  4: bernese_mountain_dog\n",
      "  5: shih-tzu\n",
      "  6: great_pyrenees\n",
      "  7: pomeranian\n",
      "  8: basenji\n",
      "  9: samoyed\n",
      "  10: airedale\n",
      "  11: tibetan_terrier\n",
      "  12: leonberg\n",
      "  13: cairn\n",
      "  14: beagle\n",
      "  15: japanese_spaniel\n",
      "  16: australian_terrier\n",
      "  17: blenheim_spaniel\n",
      "  18: miniature_pinscher\n",
      "  19: irish_wolfhound\n",
      "  20: lakeland_terrier\n",
      "  21: saluki\n",
      "  22: papillon\n",
      "  23: whippet\n",
      "  24: siberian_husky\n",
      "  25: norwegian_elkhound\n",
      "  26: pug\n",
      "  27: chow\n",
      "  28: italian_greyhound\n",
      "  29: pembroke\n",
      "  30: ibizan_hound\n",
      "  31: border_terrier\n",
      "  32: newfoundland\n",
      "  33: lhasa\n",
      "  34: silky_terrier\n",
      "  35: bedlington_terrier\n",
      "  36: dandie_dinmont\n",
      "  37: irish_setter\n",
      "  38: sealyham_terrier\n",
      "  39: rhodesian_ridgeback\n",
      "  40: old_english_sheepdog\n",
      "  41: collie\n",
      "  42: boston_bull\n",
      "  43: english_foxhound\n",
      "  44: bouvier_des_flandres\n",
      "  45: african_hunting_dog\n",
      "  46: schipperke\n",
      "  47: kelpie\n",
      "  48: weimaraner\n",
      "  49: bloodhound\n",
      "  50: bluetick\n",
      "  51: saint_bernard\n",
      "  52: labrador_retriever\n",
      "  53: chesapeake_bay_retriever\n",
      "  54: norfolk_terrier\n",
      "  55: english_setter\n",
      "  56: wire-haired_fox_terrier\n",
      "  57: kerry_blue_terrier\n",
      "  58: scotch_terrier\n",
      "  59: yorkshire_terrier\n",
      "  60: groenendael\n",
      "  61: greater_swiss_mountain_dog\n",
      "  62: irish_terrier\n",
      "  63: basset\n",
      "  64: keeshond\n",
      "  65: west_highland_white_terrier\n",
      "  66: gordon_setter\n",
      "  67: malamute\n",
      "  68: affenpinscher\n",
      "  69: toy_poodle\n",
      "  70: clumber\n",
      "  71: mexican_hairless\n",
      "  72: dingo\n",
      "  73: standard_poodle\n",
      "  74: miniature_poodle\n",
      "  75: staffordshire_bullterrier\n",
      "  76: welsh_springer_spaniel\n",
      "  77: toy_terrier\n",
      "  78: sussex_spaniel\n",
      "  79: norwich_terrier\n",
      "  80: appenzeller\n",
      "  81: irish_water_spaniel\n",
      "  82: miniature_schnauzer\n",
      "  83: black-and-tan_coonhound\n",
      "  84: cardigan\n",
      "  85: dhole\n",
      "  86: shetland_sheepdog\n",
      "  87: rottweiler\n",
      "  88: english_springer\n",
      "  89: great_dane\n",
      "  90: german_short-haired_pointer\n",
      "  91: boxer\n",
      "  92: bull_mastiff\n",
      "  93: borzoi\n",
      "  94: pekinese\n",
      "  95: cocker_spaniel\n",
      "  96: american_staffordshire_terrier\n",
      "  97: doberman\n",
      "  98: brittany_spaniel\n",
      "  99: malinois\n",
      "  100: standard_schnauzer\n",
      "  101: flat-coated_retriever\n",
      "  102: redbone\n",
      "  103: border_collie\n",
      "  104: curly-coated_retriever\n",
      "  105: kuvasz\n",
      "  106: chihuahua\n",
      "  107: soft-coated_wheaten_terrier\n",
      "  108: french_bulldog\n",
      "  109: vizsla\n",
      "  110: tibetan_mastiff\n",
      "  111: german_shepherd\n",
      "  112: giant_schnauzer\n",
      "  113: walker_hound\n",
      "  114: otterhound\n",
      "  115: golden_retriever\n",
      "  116: brabancon_griffon\n",
      "  117: komondor\n",
      "  118: briard\n",
      "  119: eskimo_dog\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Count all breeds\n",
    "def countBreeds(df):\n",
    "    df1 = df_labels.groupby(\"breed\")[\"id\"].count().reset_index(name=\"count\")\n",
    "    df1 = df1.sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "    df1.insert(0, 'breed_id', df1.index)\n",
    "    return df1\n",
    "\n",
    "df_breeds = countBreeds(df_labels)\n",
    "print(df_breeds.info())\n",
    "print(); print(df_breeds.head())\n",
    "\n",
    "NumClasses = int(df_breeds.shape[0])\n",
    "print('\\nNum classes:', NumClasses)\n",
    "\n",
    "selected_breeds = df_breeds['breed'].tolist()\n",
    "\n",
    "# dict_bid_fw = dict(df_breeds[['breed', 'breed_id']].values)\n",
    "dict_bid_bw = dict(df_breeds[['breed_id', 'breed']].values)\n",
    "\n",
    "def prettyPrint(d, indent=0):\n",
    "    print('{')\n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, dict):\n",
    "            print('  ' * indent + str(key))\n",
    "            prettyPrint(value, indent+1)\n",
    "        else:\n",
    "            print('  ' * (indent+1) + f\"{key}: {value}\")\n",
    "    print('}')\n",
    "                \n",
    "print('\\nBreeds dict backward:'); \n",
    "prettyPrint(dict_bid_bw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image shape: torch.Size([100, 3, 224, 224])\n",
      "\n",
      "Image ids\n",
      "  000621fb3cbb32d8935728e48679680e\n",
      "  00102ee9d8eb90812350685311fe5890\n",
      "  0012a730dfa437f5f3613fb75efcd4ce\n",
      "  001510bc8570bbeee98c8d80c8a95ec1\n",
      "  001a5f3114548acdefa3d4da05474c2e\n",
      "  00225dcd3e4d2410dd53239f95c0352f\n",
      "  002c2a3117c2193b4d26400ce431eebd\n",
      "  002c58d413a521ae8d1a5daeb35fc803\n",
      "  002f80396f1e3db687c5932d7978b196\n",
      "  0036c6bcec6031be9e62a257b1c3c442\n",
      "  0041940322116ae58c38130f5a6f71f9\n",
      "  0042d6bf3e5f3700865886db32689436\n",
      "  004476c96f575879af4af471af65cae8\n",
      "  00485d47de966a9437ad3b33ac193b6f\n",
      "  00496f65de6cc319145ce97bd6e90360\n",
      "  004bf14426d1a830d459a9e0c0721309\n",
      "  004c3721eb88358f462cdcec6b2380b7\n",
      "  00559f56aab7e0a7749220f6aed65162\n",
      "  005b281f1a4d6f29d527c9585e9bd33c\n",
      "  005b6c6c76fefd6b458ef6fb6e54da6e\n",
      "  006870b49353779b25eeb91fed43c31a\n",
      "  0068f3a21b159ece126a28580cdad7a0\n",
      "  0069b1cc4546fc98f84f981bf9a0696a\n",
      "  0077bc3c63486ff09d3774d956af8f76\n",
      "  00780e5d2bf4f7e4b5f96d08ddde669a\n",
      "  007ed71136966728f5c0936e23c8286b\n",
      "  0081831ceb49cd64212c32b884036b82\n",
      "  00846c0edd5aa4f10ee5e9b84d7310a6\n",
      "  0092bd9e90a13403373fc0e9e1218938\n",
      "  009a3c4f6626e4750f74ceb8e8ed8760\n",
      "  00a3edd22dc7859c487a64777fc8d093\n",
      "  00a558277e1f03b71d8c813e03344ddf\n",
      "  00a6892e5c7f92c1f465e213fd904582\n",
      "  00b29dbc49177cd4faeac3c485330af9\n",
      "  00b43aa6064fa6733a391d41fe4c6803\n",
      "  00b965deff7c711cfeaa927ce52f8653\n",
      "  00bbbcb2bf285af6304bd4da0c10299e\n",
      "  00bbfaa5b2bff32a3dc8ce1563e484a3\n",
      "  00c14d34a725db12068402e4ce714d4c\n",
      "  00c610a43b661e4fc612d06db96ce258\n",
      "  00c6e480ca61e3d2da272d7b6bee0a9e\n",
      "  00d3ae5326883e4330fd4af3db8f2997\n",
      "  00d6e16493e6af2886292fa8823bdfe0\n",
      "  00d9537c197b7c4c4cdbd5d03c34b58a\n",
      "  00e3fd599b69899cba0a4939f66a1745\n",
      "  00e51308952848ae67b3ff8b53895119\n",
      "  00e71e327e114433191f34054c6bf6f5\n",
      "  00e7391275cb71dd573ad429d3d933d6\n",
      "  00e98b2021242014c466574d5b6ebc0c\n",
      "  00fe03513ca95a133d4ad7cbbdc1da28\n",
      "  00ff1cba799d51b0042915e33a823b28\n",
      "  010a0d3eb52479f4af474662ee0f67ee\n",
      "  0110fb82ad93572bd6f5dae4b048037d\n",
      "  011891ea9c5d8f160e21daa97f774e7f\n",
      "  012ca7efe684c5cdfb83f35e8fbafe1b\n",
      "  0130e4d83375e4b33a6db2c2b59324d5\n",
      "  01335e3d4849ec81cc1578aa915227b9\n",
      "  0137b490cbe148729cdff53326a41504\n",
      "  0138c08d1623fc7c8e8ece99ca1ce78e\n",
      "  013c030b78079c77fbe8133d74d58acd\n",
      "  013c469ce5bd1117b248883dee30a38d\n",
      "  0143aa47cc7cb5926cc32daf3a6a3b3d\n",
      "  014da249523b906a840f8c33ae055cf3\n",
      "  015a6039ba5ca1a76b7f856c654ee9a1\n",
      "  015a6a8a46302983fad0e5ea258b351a\n",
      "  01641548f4a2988ee7a2ec783d177a98\n",
      "  0169ed6715e26c0c5fb460941c8d3bee\n",
      "  017aa2284919402a4da3032182417622\n",
      "  018103a0629c87eeba67eda67c235cb7\n",
      "  0187ee2ec2367ed4fd060cca9681742a\n",
      "  019545d00bc1a0641d7471c1afde42c4\n",
      "  0196984af8d9e25aaff3dd2a9df372fa\n",
      "  01b09dccd56851eadb6ac3f2add3c822\n",
      "  01b2d28b2d793d02043220cb469d87e5\n",
      "  01b52961a39ed2f83e5b18ca9e069850\n",
      "  01b6b6a0a6fddda170de5b1db776326a\n",
      "  01b7405f4c920e98e0a462f3a99b542c\n",
      "  01b77c99d6ecf7aee49c8ec326bcb07c\n",
      "  01c5377f30398c17dd5b23a32fa66760\n",
      "  01cb4c4d181a23e157429168e948fe5a\n",
      "  01cb83d33e905e825df41b88dd4ef277\n",
      "  01cd792c6360ff9300ca60be40487549\n",
      "  01ce0bd1dff470548ac5c5122aa2d44f\n",
      "  01d333d5c288be97bffd76005f559f41\n",
      "  01d5ffa4de01074483149bec0f6e5a59\n",
      "  01d9fc5195f7cd2ca9e12b9c9e3eaca2\n",
      "  01deef5e85f2573f4689780b94aa58c0\n",
      "  01df86b786d0a5b4cde3713a1314ceaf\n",
      "  01f3be56aaa63fb47fd576a17f1f60b6\n",
      "  01fc8d4fec16bb8dcb5a0e60db1dc7fb\n",
      "  0201de3d74ad48774e0bd55d04d2966d\n",
      "  02094b19b383b85741353fc00c085895\n",
      "  020999e4f2b9509d90a59de565a0c723\n",
      "  020d14c04769cdc0aba82befd41816da\n",
      "  02113c6c2c25cb7bfe1d743c17a93b0d\n",
      "  021ad1825ea4fc5c0af6edc805fbcb8e\n",
      "  02215f26ca6ece8786daecc15c60e774\n",
      "  0223272e92ee6b7e9fc4cf48dbd7d167\n",
      "  023c0a9675c4e09e7de76be0fad3d52f\n",
      "  0243ae2c5882404028214ebc9806b453\n",
      "\n",
      "Image shape: torch.Size([3, 224, 224])\n",
      "\n",
      "Image tensor:\n",
      "tensor([[[0.4000, 0.4196, 0.4039,  ..., 0.3843, 0.3882, 0.3294],\n",
      "         [0.3804, 0.4235, 0.3529,  ..., 0.3686, 0.3412, 0.3137],\n",
      "         [0.3608, 0.3569, 0.3255,  ..., 0.3059, 0.3922, 0.3765],\n",
      "         ...,\n",
      "         [0.1451, 0.2667, 0.5059,  ..., 0.0824, 0.0784, 0.1490],\n",
      "         [0.0549, 0.1373, 0.2392,  ..., 0.0980, 0.1333, 0.1608],\n",
      "         [0.0980, 0.0863, 0.1373,  ..., 0.1176, 0.0745, 0.1098]],\n",
      "\n",
      "        [[0.4353, 0.4235, 0.3765,  ..., 0.4314, 0.4235, 0.3647],\n",
      "         [0.4157, 0.4314, 0.3333,  ..., 0.4196, 0.3922, 0.3686],\n",
      "         [0.3882, 0.3647, 0.3137,  ..., 0.3725, 0.4627, 0.4510],\n",
      "         ...,\n",
      "         [0.1961, 0.2627, 0.5020,  ..., 0.1686, 0.1686, 0.2431],\n",
      "         [0.1608, 0.1961, 0.2941,  ..., 0.1882, 0.2275, 0.2549],\n",
      "         [0.2353, 0.1882, 0.2275,  ..., 0.1922, 0.1529, 0.1961]],\n",
      "\n",
      "        [[0.2588, 0.2980, 0.3098,  ..., 0.0275, 0.0510, 0.0510],\n",
      "         [0.2000, 0.2588, 0.2157,  ..., 0.0314, 0.0196, 0.0157],\n",
      "         [0.1373, 0.1529, 0.1490,  ..., 0.0235, 0.0745, 0.0275],\n",
      "         ...,\n",
      "         [0.0902, 0.2353, 0.4902,  ..., 0.0824, 0.0745, 0.1451],\n",
      "         [0.0471, 0.1216, 0.2078,  ..., 0.0902, 0.1216, 0.1490],\n",
      "         [0.0902, 0.0667, 0.1020,  ..., 0.1020, 0.0588, 0.0980]]])\n"
     ]
    }
   ],
   "source": [
    "# Build dataset\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class myDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path, transform=None):\n",
    "        \n",
    "        img_list = [\n",
    "            join(path, f) \\\n",
    "            if f.endswith('.jpg') and isfile(join(path, f)) else None \\\n",
    "            for f in listdir(path)\n",
    "        ]\n",
    "\n",
    "        self.len = len(img_list)\n",
    "        self.images = img_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.images[index]\n",
    "        img_pil = Image.open(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img_tensor = self.transform(img_pil)\n",
    "\n",
    "        iid = split(img)[1].replace('.jpg', '')\n",
    "        \n",
    "        return [img_tensor, iid]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    \n",
    "TestPath = Params['TestPath']\n",
    "# BatchSize = Params['BatchSize']\n",
    "BatchSize = 100\n",
    "    \n",
    "dataSet = myDataset(TestPath, transform=transform)\n",
    "dataLoader = DataLoader(dataSet, batch_size=BatchSize, shuffle=False)\n",
    "dataSize = len(dataSet)\n",
    "\n",
    "imgs, iids = next(iter(dataLoader))\n",
    "print('\\nImage shape:', imgs.shape)\n",
    "\n",
    "print('\\nImage ids')\n",
    "id_list = [''.join(iid) for iid in iids]\n",
    "print('  '+'\\n  '.join(id_list))\n",
    "\n",
    "img = imgs[0]\n",
    "print('\\nImage shape:', img.shape)\n",
    "\n",
    "print('\\nImage tensor:')\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Use GPU for train\n",
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=120, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Build Model \n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# freeze all model parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# New final layer with NumClasses\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, NumClasses)\n",
    "\n",
    "# load pretrained mode\n",
    "PreTranPath = Params['PreTrainPath']\n",
    "PreTranFile = Params['PreTrainFile']\n",
    "f_abspath = join(PreTranPath, PreTranFile)\n",
    "model.load_state_dict(torch.load(f_abspath))\n",
    "\n",
    "if use_gpu: model = model.cuda()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing...\n",
      "\n",
      "Probs:\n",
      "torch.Size([100, 120])\n",
      "tensor([[1.2100e-03, 2.0992e-01, 8.4855e-03,  ..., 6.6440e-03, 4.0181e-03,\n",
      "         3.9533e-03],\n",
      "        [1.1271e-04, 3.2042e-03, 8.7192e-05,  ..., 6.2201e-04, 2.6369e-04,\n",
      "         1.3375e-02],\n",
      "        [1.5161e-02, 1.5351e-02, 2.8774e-02,  ..., 1.0469e-02, 7.5163e-03,\n",
      "         6.3521e-03],\n",
      "        ...,\n",
      "        [4.6673e-03, 3.1670e-03, 2.1943e-03,  ..., 4.0342e-03, 8.4376e-03,\n",
      "         1.0519e-02],\n",
      "        [7.8491e-03, 8.4818e-04, 8.0299e-04,  ..., 2.7263e-03, 1.3364e-03,\n",
      "         4.5447e-03],\n",
      "        [5.8779e-03, 8.7829e-02, 1.8355e-03,  ..., 7.9751e-03, 2.7250e-02,\n",
      "         3.4388e-03]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "\n",
      "Preds:\n",
      "torch.Size([100])\n",
      "tensor([  1,   9,  93,  26,   1,  35,  13,   9,  44,  70,   1,  38,   9,   7,\n",
      "        106,  32,  77,   1,  23,  21,  58,  24,  71,   1,  37,  46,  48,  23,\n",
      "          1,  10,  45,   6,  70,   1,  90,  41,  15,  68,  51,   1,  35,   0,\n",
      "         91,   1,  45,   4,   5,  22,  18,  48,  14,  11,  67,  17,  48,  29,\n",
      "         48,  89,   1,  45,  77,   6,  19,  48,   1,  69,   9,  69,   1,  95,\n",
      "         68,   6,  14, 106,  65,  61,  26,  35,  95,   1,  23,  44,  85,   1,\n",
      "         48,  48,  26,  45,  63,   9,   9,  79,  26,   1,  97,   9, 106,  32,\n",
      "         45,   1], device='cuda:0')\n",
      "\n",
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, \n",
      "Testing time:   1.979823 minutes\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10357 entries, 0 to 56\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          10357 non-null  object\n",
      " 1   prediction  10357 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 242.7+ KB\n",
      "None\n",
      "\n",
      "                                 id   prediction\n",
      "0  000621fb3cbb32d8935728e48679680e  maltese_dog\n",
      "1  00102ee9d8eb90812350685311fe5890      samoyed\n",
      "2  0012a730dfa437f5f3613fb75efcd4ce       borzoi\n",
      "3  001510bc8570bbeee98c8d80c8a95ec1          pug\n",
      "4  001a5f3114548acdefa3d4da05474c2e  maltese_dog\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10357 entries, 0 to 56\n",
      "Columns: 121 entries, id to eskimo_dog\n",
      "dtypes: float64(120), object(1)\n",
      "memory usage: 9.6+ MB\n",
      "None\n",
      "\n",
      "                                 id  scottish_deerhound  maltese_dog  \\\n",
      "0  000621fb3cbb32d8935728e48679680e            0.001210     0.209923   \n",
      "1  00102ee9d8eb90812350685311fe5890            0.000113     0.003204   \n",
      "2  0012a730dfa437f5f3613fb75efcd4ce            0.015161     0.015351   \n",
      "3  001510bc8570bbeee98c8d80c8a95ec1            0.005546     0.018933   \n",
      "4  001a5f3114548acdefa3d4da05474c2e            0.002083     0.042891   \n",
      "\n",
      "   afghan_hound  entlebucher  bernese_mountain_dog  shih-tzu  great_pyrenees  \\\n",
      "0      0.008485     0.003056              0.002199  0.019800        0.019304   \n",
      "1      0.000087     0.000158              0.000268  0.000672        0.027959   \n",
      "2      0.028774     0.003259              0.001331  0.003363        0.039209   \n",
      "3      0.003364     0.004688              0.003882  0.009711        0.008633   \n",
      "4      0.002911     0.001595              0.003642  0.033354        0.032919   \n",
      "\n",
      "   pomeranian   basenji  ...  tibetan_mastiff  german_shepherd  \\\n",
      "0    0.018099  0.006482  ...         0.002298         0.004322   \n",
      "1    0.015706  0.000478  ...         0.000919         0.000564   \n",
      "2    0.003179  0.005325  ...         0.002740         0.004361   \n",
      "3    0.014801  0.009812  ...         0.003173         0.009912   \n",
      "4    0.012229  0.001866  ...         0.015089         0.003477   \n",
      "\n",
      "   giant_schnauzer  walker_hound  otterhound  golden_retriever  \\\n",
      "0         0.003103      0.003281    0.002138          0.010411   \n",
      "1         0.000128      0.000514    0.000151          0.000662   \n",
      "2         0.006393      0.005626    0.006581          0.012450   \n",
      "3         0.010624      0.003074    0.001554          0.008033   \n",
      "4         0.007027      0.002757    0.009351          0.011091   \n",
      "\n",
      "   brabancon_griffon  komondor    briard  eskimo_dog  \n",
      "0           0.003344  0.006644  0.004018    0.003953  \n",
      "1           0.000921  0.000622  0.000264    0.013375  \n",
      "2           0.004070  0.010469  0.007516    0.006352  \n",
      "3           0.007964  0.003399  0.004909    0.007906  \n",
      "4           0.006827  0.011208  0.014289    0.004949  \n",
      "\n",
      "[5 rows x 121 columns]\n"
     ]
    }
   ],
   "source": [
    "# Pediction\n",
    "import torch.nn.functional as nnf\n",
    "\n",
    "# Output submission\n",
    "fname_submission = 'submission.csv'\n",
    "f_abspath = join(OutPath, fname_submission)\n",
    "\n",
    "cols_preds = ['id', 'prediction']\n",
    "df_preds = pd.DataFrame(columns=cols_preds)\n",
    "\n",
    "cols_probs = ['id'] + selected_breeds\n",
    "df_probs = pd.DataFrame(columns=cols_probs)\n",
    "\n",
    "start_time = time.time()\n",
    "print('Start testing...')\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for i, (inputs, iids) in enumerate(dataLoader):\n",
    "\n",
    "    inputs = Variable(inputs.cuda())\n",
    "    iid_list = list(iids)\n",
    "    \n",
    "    with torch.set_grad_enabled(True):\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        \n",
    "        if i == 0:\n",
    "            # print(); print(len(iid_list)); print('\\n'.join(iid_list))\n",
    "            print('\\nProbs:'); print(probs.shape); print(probs)\n",
    "            print('\\nPreds:'); print(preds.shape); print(preds)\n",
    "            print()\n",
    "    \n",
    "    pred_list = preds.tolist()\n",
    "    pred_breeds = [dict_bid_bw.get(x) for x in pred_list]\n",
    "    \n",
    "    df_tmp = pd.DataFrame({\n",
    "        'id': iid_list,\n",
    "        'prediction': pred_breeds\n",
    "    })\n",
    "    df_preds = df_preds.append(df_tmp)\n",
    "\n",
    "    df_tmp = pd.DataFrame({'id': iid_list})\n",
    "    df_tmp[selected_breeds] = pd.DataFrame(probs.tolist())\n",
    "    df_probs = df_probs.append(df_tmp)\n",
    "\n",
    "    print(i, end=', ')\n",
    "    \n",
    "print()\n",
    "print('Testing time: {:10f} minutes'.format((time.time()-start_time)/60))    \n",
    "\n",
    "print(); print(df_preds.info())\n",
    "print(); print(df_preds.head())\n",
    "\n",
    "print(); print(df_probs.info())\n",
    "print(); print(df_probs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "currDT = datetime.now()\n",
    "currStr = currDT.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "fname = 'Prediction_{}.csv'.format(currStr)\n",
    "df_preds.to_csv(join(OutPath, fname), index=False)\n",
    "\n",
    "fname = 'Probability_{}.csv'.format(currStr)\n",
    "df_probs.to_csv(join(OutPath, fname), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
