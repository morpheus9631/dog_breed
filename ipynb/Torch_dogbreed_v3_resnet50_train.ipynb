{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.5.1\n",
      "Torchvision Version:  0.6.1\n"
     ]
    }
   ],
   "source": [
    "# From: https://www.kaggle.com/c/dog-breed-identification/data\n",
    "# Author: Morpheus Hsieh (morpheus.hsieh@gmail.com)\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import os, sys\n",
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "from os import listdir\n",
    "from os.path import join, exists, isfile\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "{\n",
      "  'DataPath'    : 'D:\\GitWork\\dog_breed\\data',\n",
      "  'OutPath'     : 'D:\\GitWork\\dog_breed\\output',\n",
      "  'ProcPath'    : 'D:\\GitWork\\dog_breed\\processed',\n",
      "  'PreTrainPath': 'D:\\GitWork\\dog_breed\\pretrained',\n",
      "  'PreTrainFile': '',\n",
      "  'TestPath'    : 'D:\\Dataset\\dog-breed-identification\\test',\n",
      "  'TrainPath'   : 'D:\\Dataset\\dog-breed-identification\\train',\n",
      "  'CsvLabel'    : 'labels.csv',\n",
      "  'BatchSize'   : 16,\n",
      "  'FracForTrain': 0.8\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "Params = {\n",
    "    'DataPath'    : r'D:\\GitWork\\dog_breed\\data',\n",
    "    'OutPath'     : r'D:\\GitWork\\dog_breed\\output',\n",
    "    'ProcPath'    : r'D:\\GitWork\\dog_breed\\processed',\n",
    "    'PreTrainPath': r'D:\\GitWork\\dog_breed\\pretrained',\n",
    "    'PreTrainFile': '',\n",
    "    'TestPath'    : r'D:\\Dataset\\dog-breed-identification\\test',\n",
    "    'TrainPath'   : r'D:\\Dataset\\dog-breed-identification\\train',\n",
    "    'CsvLabel'    : 'labels.csv',\n",
    "    'BatchSize'   : 16,\n",
    "    'FracForTrain': 0.8\n",
    "}\n",
    "\n",
    "\n",
    "def prettyDict(dic, indent=2):\n",
    "    array = []\n",
    "    key_maxlen = 0\n",
    "    item_cnt = 0\n",
    "    item_size = len(dic)\n",
    "    split_str = ': '\n",
    "    \n",
    "    for key, val in dic.items():\n",
    "        if key_maxlen < len(str(key)): \n",
    "            key_maxlen = len(str(key))\n",
    "        \n",
    "        tmpstr = ''\n",
    "        tmpstr += f\"'{key}'\" if isinstance(key, str) else f\"{key}\"\n",
    "        tmpstr += split_str\n",
    "        tmpstr += f\"'{val}'\" if isinstance(val, str) else f\"{val}\"\n",
    "\n",
    "        item_cnt += 1\n",
    "        if item_cnt < item_size: tmpstr += ','\n",
    "        array.append(tmpstr)\n",
    "    \n",
    "    for i in range(len(array)):\n",
    "        inStr = array[i]\n",
    "        ary = inStr.split(split_str)\n",
    "        key = ary[0].ljust(key_maxlen+2)\n",
    "        val = ary[1]\n",
    "        array[i] = (' '*indent) + key + ': ' + val\n",
    "        \n",
    "    outstr = '{\\n' + '\\n'.join(array) + '\\n}'\n",
    "    return outstr\n",
    "\n",
    "outstr = prettyDict(Params)\n",
    "print('Parameters:')\n",
    "print(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10222 entries, 0 to 10221\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      10222 non-null  object\n",
      " 1   breed   10222 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 159.8+ KB\n",
      "None\n",
      "\n",
      "                                 id             breed\n",
      "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
      "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
      "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
      "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
      "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever\n"
     ]
    }
   ],
   "source": [
    "# Read breed information from csv\n",
    "DataPath = Params.get('DataPath')\n",
    "csv_labels = Params.get('CsvLabel')\n",
    "f_abspath = join(DataPath, csv_labels)\n",
    "\n",
    "df_labels = pd.read_csv(f_abspath)\n",
    "\n",
    "print(df_labels.info())\n",
    "print()\n",
    "print(df_labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120 entries, 0 to 119\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   breed_id  120 non-null    int64 \n",
      " 1   breed     120 non-null    object\n",
      " 2   count     120 non-null    int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 2.9+ KB\n",
      "None\n",
      "\n",
      "   breed_id                 breed  count\n",
      "0         0    scottish_deerhound    126\n",
      "1         1           maltese_dog    117\n",
      "2         2          afghan_hound    116\n",
      "3         3           entlebucher    115\n",
      "4         4  bernese_mountain_dog    114\n",
      "\n",
      "Num classes: 120\n"
     ]
    }
   ],
   "source": [
    "# Count all breeds\n",
    "def countBreeds(df):\n",
    "    df1 = df_labels.groupby(\"breed\")[\"id\"].count().reset_index(name=\"count\")\n",
    "    df1 = df1.sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "    df1.insert(0, 'breed_id', df1.index)\n",
    "    return df1\n",
    "\n",
    "df_breeds = countBreeds(df_labels)\n",
    "print(df_breeds.info())\n",
    "print()\n",
    "print(df_breeds.head())\n",
    "\n",
    "NumClasses = int(df_breeds.shape[0])\n",
    "print('\\nNum classes:', NumClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10222 entries, 0 to 10221\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   image     10222 non-null  object\n",
      " 1   breed_id  10222 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 159.8+ KB\n",
      "None\n",
      "                                               image  breed_id\n",
      "0  D:\\Dataset\\dog-breed-identification\\train\\000b...        42\n",
      "1  D:\\Dataset\\dog-breed-identification\\train\\0015...        72\n",
      "2  D:\\Dataset\\dog-breed-identification\\train\\001c...        94\n",
      "3  D:\\Dataset\\dog-breed-identification\\train\\0021...        50\n",
      "4  D:\\Dataset\\dog-breed-identification\\train\\0021...       115\n"
     ]
    }
   ],
   "source": [
    "# Process labels\n",
    "\n",
    "dict_bid_fw = dict(df_breeds[['breed', 'breed_id']].values)\n",
    "# print(dict_bid_fw)\n",
    "\n",
    "dict_bid_bw = dict(df_breeds[['breed_id', 'breed']].values)\n",
    "# print(dict_bid_bw)\n",
    "\n",
    "# Build processed labels file\n",
    "df_data = pd.DataFrame(columns=['image', 'breed_id'])\n",
    "df_data['breed_id'] = df_labels.breed.map(dict_bid_fw)\n",
    "\n",
    "TranPath = Params['TrainPath']\n",
    "\n",
    "df_data['image'] = df_labels.apply (\n",
    "    lambda row: join(TranPath, row['id']+'.jpg') \\\n",
    "    if exists(join(TranPath, row['id']+'.jpg')) else None, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(df_data.info())\n",
    "print(df_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSet size: {'train': 8177, 'valid': 2045}\n",
      "\n",
      "Image shape: torch.Size([16, 3, 224, 224])\n",
      "Label shape: torch.Size([16])\n",
      "\n",
      "Image iid:\n",
      "  896ae4eda6310c5fa223131ac7574494\n",
      "  adc5daa413e246287aacf9b7f6e16d36\n",
      "  9c8bab83db2da5aad21f41e44643de64\n",
      "  5f11e117f4ba6ed026682fe516651c59\n",
      "  dd52583a6a9bfdcc5278c5d61a57b7e1\n",
      "  c9be1b14a664fab3d09d0ca4b8a79cbf\n",
      "  8befc822b56b744d72872428a0ef4851\n",
      "  278739637271fe972aa9a62404685a24\n",
      "  e4b586f1a120bba42545d866d45d0602\n",
      "  dfc97c3d7a59ad4d89e791e6ab14c49f\n",
      "  78e7aa41b7f4326a7f582426a3fdb151\n",
      "  c3487bbf17be7def166026f875edbdc0\n",
      "  bbb3573b1f9a2f3ab1b1d62cc26a7b88\n",
      "  c2a5c44a3cb6d8e5fc36ff0bb8640776\n",
      "  d5b01922a98bd60cd867e7b6d62039f2\n",
      "  5df814fe3a8b8b678baf9afe62998291\n",
      "\n",
      "Image shape: torch.Size([3, 224, 224])\n",
      "\n",
      "tensor([[[-0.2513, -0.1657, -0.6452,  ..., -1.5528, -1.2959, -0.5424],\n",
      "         [-0.9877, -0.6794, -0.5082,  ..., -1.2274, -0.8335, -0.2171],\n",
      "         [-1.0733, -1.4500, -0.4911,  ..., -0.8849, -0.4226, -0.0801],\n",
      "         ...,\n",
      "         [ 0.8104,  0.5707,  0.7248,  ..., -0.5938,  0.3994,  0.5536],\n",
      "         [ 0.8961,  0.5707,  0.5536,  ...,  0.5364,  0.6392,  0.7591],\n",
      "         [ 0.6563,  0.5707,  0.5022,  ...,  0.7419,  0.9646,  1.0502]],\n",
      "\n",
      "        [[-0.4076, -0.3200, -0.8102,  ..., -1.5980, -1.3004, -0.5126],\n",
      "         [-1.1253, -0.7927, -0.6352,  ..., -1.2654, -0.8277, -0.1975],\n",
      "         [-1.1078, -1.4930, -0.5476,  ..., -0.8978, -0.4251, -0.0574],\n",
      "         ...,\n",
      "         [ 0.7129,  0.4678,  0.6254,  ..., -0.6176,  0.3627,  0.5203],\n",
      "         [ 0.8004,  0.4678,  0.4503,  ...,  0.4503,  0.5553,  0.6604],\n",
      "         [ 0.5553,  0.4678,  0.3978,  ...,  0.6078,  0.8004,  0.8880]],\n",
      "\n",
      "        [[-0.2881, -0.2184, -0.7587,  ..., -1.5081, -1.3687, -0.6367],\n",
      "         [-0.9504, -0.6715, -0.5495,  ..., -1.1944, -0.9330, -0.3578],\n",
      "         [-0.9330, -1.3164, -0.4275,  ..., -0.8807, -0.5844, -0.2881],\n",
      "         ...,\n",
      "         [ 0.7402,  0.4962,  0.6879,  ..., -0.5670,  0.1825,  0.2696],\n",
      "         [ 0.8274,  0.5136,  0.5136,  ...,  0.4439,  0.3916,  0.4265],\n",
      "         [ 0.5834,  0.4962,  0.4614,  ...,  0.5136,  0.6356,  0.6879]]])\n",
      "\n",
      "Labels: tensor(34)\n"
     ]
    }
   ],
   "source": [
    "# Create dataset\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean = [0.485, 0.456, 0.406],\n",
    "        std  = [0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "class myDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, phase='train', frac=0.8, transform=None):\n",
    "        \n",
    "        num_rows = df.shape[0]\n",
    "        train_len = int(float(frac) * float(num_rows))\n",
    "        valid_len = num_rows - train_len\n",
    "        \n",
    "        #  data = df.head(train_len) if phase=='train' else df.tail(valid_len)\n",
    "        idx_ary = np.arange(len(df))\n",
    "        idx_ary_rand = np.random.permutation(idx_ary) # random shuffle\n",
    "        \n",
    "        data_len = train_len if phase=='train' else valid_len\n",
    "        data = df.loc[idx_ary_rand[:data_len]]\n",
    "        \n",
    "        self.images = data['image'].tolist()\n",
    "        self.labels = data['breed_id'].tolist()\n",
    "\n",
    "        self.transform = transform\n",
    "        self.len = len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        f_abspath = self.images[index]\n",
    "        img_pil = Image.open(f_abspath)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img_pil)\n",
    "\n",
    "        lbl = int(self.labels[index])\n",
    "        iid = os.path.split(f_abspath)[1].replace('.jpg', '')\n",
    "        \n",
    "        return [img, lbl, iid]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "\n",
    "frac = Params['FracForTrain']\n",
    "\n",
    "phases = ['train', 'valid']\n",
    "dataSet = { \n",
    "    x: myDataset(df_data, phase=x, frac=frac, transform=transform) for x in phases \n",
    "}\n",
    "\n",
    "BatchSize = Params['BatchSize']\n",
    "dataLoader = {\n",
    "    x: DataLoader(dataSet[x], batch_size=BatchSize, shuffle=True) for x in phases\n",
    "}\n",
    "\n",
    "dataSizes = { x: len(dataSet[x]) for x in phases }\n",
    "print('DataSet size:', dataSizes)\n",
    "\n",
    "trainLoader = dataLoader['train']\n",
    "imgs, lbls, iids = next(iter(trainLoader))\n",
    "print('\\nImage shape:', imgs.size())\n",
    "print('Label shape:', lbls.size())\n",
    "\n",
    "print('\\nImage iid:')\n",
    "id_list = [''.join(iid) for iid in iids]\n",
    "print('  '+'\\n  '.join(id_list))\n",
    "\n",
    "img = imgs[0]\n",
    "print('\\nImage shape:', img.shape)\n",
    "print(); print(img)\n",
    "\n",
    "print('\\nLabels:', lbls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Use GPU for train\n",
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=120, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Build Model\n",
    "def buildModel(use_gpu, numClasses, preTrainModel=None):\n",
    "    model = models.resnet50(pretrained=True)\n",
    "\n",
    "    # freeze all model parameters\n",
    "    for param in model.parameters():\n",
    "        model.requires_grad = False\n",
    "\n",
    "    # new final layer with 16 classes\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, numClasses)\n",
    "    \n",
    "    if preTrainModel is not None:\n",
    "        model.load_state_dict(preTrainModel)\n",
    "        \n",
    "    if use_gpu: \n",
    "        model = model.cuda()\n",
    "        \n",
    "    return model\n",
    "\n",
    "\n",
    "TrainPath = Params['PreTrainPath']\n",
    "TrainFile = Params['PreTrainFile']\n",
    "f_pretrain = join(TrainPath, TrainFile)\n",
    "\n",
    "pretrain_model = None\n",
    "if exists(f_pretrain) and isfile(f_pretrain):\n",
    "    pretrain_model = torch.load(join(path, fname))\n",
    "\n",
    "model = buildModel(use_gpu, NumClasses, preTrainModel=pretrain_model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "conv1.weight \t torch.Size([64, 3, 7, 7])\n",
      "bn1.weight \t torch.Size([64])\n",
      "bn1.bias \t torch.Size([64])\n",
      "bn1.running_mean \t torch.Size([64])\n",
      "bn1.running_var \t torch.Size([64])\n",
      "bn1.num_batches_tracked \t torch.Size([])\n",
      "layer1.0.conv1.weight \t torch.Size([64, 64, 1, 1])\n",
      "layer1.0.bn1.weight \t torch.Size([64])\n",
      "layer1.0.bn1.bias \t torch.Size([64])\n",
      "layer1.0.bn1.running_mean \t torch.Size([64])\n",
      "layer1.0.bn1.running_var \t torch.Size([64])\n",
      "layer1.0.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer1.0.conv2.weight \t torch.Size([64, 64, 3, 3])\n",
      "layer1.0.bn2.weight \t torch.Size([64])\n",
      "layer1.0.bn2.bias \t torch.Size([64])\n",
      "layer1.0.bn2.running_mean \t torch.Size([64])\n",
      "layer1.0.bn2.running_var \t torch.Size([64])\n",
      "layer1.0.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer1.0.conv3.weight \t torch.Size([256, 64, 1, 1])\n",
      "layer1.0.bn3.weight \t torch.Size([256])\n",
      "layer1.0.bn3.bias \t torch.Size([256])\n",
      "layer1.0.bn3.running_mean \t torch.Size([256])\n",
      "layer1.0.bn3.running_var \t torch.Size([256])\n",
      "layer1.0.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer1.0.downsample.0.weight \t torch.Size([256, 64, 1, 1])\n",
      "layer1.0.downsample.1.weight \t torch.Size([256])\n",
      "layer1.0.downsample.1.bias \t torch.Size([256])\n",
      "layer1.0.downsample.1.running_mean \t torch.Size([256])\n",
      "layer1.0.downsample.1.running_var \t torch.Size([256])\n",
      "layer1.0.downsample.1.num_batches_tracked \t torch.Size([])\n",
      "layer1.1.conv1.weight \t torch.Size([64, 256, 1, 1])\n",
      "layer1.1.bn1.weight \t torch.Size([64])\n",
      "layer1.1.bn1.bias \t torch.Size([64])\n",
      "layer1.1.bn1.running_mean \t torch.Size([64])\n",
      "layer1.1.bn1.running_var \t torch.Size([64])\n",
      "layer1.1.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer1.1.conv2.weight \t torch.Size([64, 64, 3, 3])\n",
      "layer1.1.bn2.weight \t torch.Size([64])\n",
      "layer1.1.bn2.bias \t torch.Size([64])\n",
      "layer1.1.bn2.running_mean \t torch.Size([64])\n",
      "layer1.1.bn2.running_var \t torch.Size([64])\n",
      "layer1.1.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer1.1.conv3.weight \t torch.Size([256, 64, 1, 1])\n",
      "layer1.1.bn3.weight \t torch.Size([256])\n",
      "layer1.1.bn3.bias \t torch.Size([256])\n",
      "layer1.1.bn3.running_mean \t torch.Size([256])\n",
      "layer1.1.bn3.running_var \t torch.Size([256])\n",
      "layer1.1.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer1.2.conv1.weight \t torch.Size([64, 256, 1, 1])\n",
      "layer1.2.bn1.weight \t torch.Size([64])\n",
      "layer1.2.bn1.bias \t torch.Size([64])\n",
      "layer1.2.bn1.running_mean \t torch.Size([64])\n",
      "layer1.2.bn1.running_var \t torch.Size([64])\n",
      "layer1.2.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer1.2.conv2.weight \t torch.Size([64, 64, 3, 3])\n",
      "layer1.2.bn2.weight \t torch.Size([64])\n",
      "layer1.2.bn2.bias \t torch.Size([64])\n",
      "layer1.2.bn2.running_mean \t torch.Size([64])\n",
      "layer1.2.bn2.running_var \t torch.Size([64])\n",
      "layer1.2.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer1.2.conv3.weight \t torch.Size([256, 64, 1, 1])\n",
      "layer1.2.bn3.weight \t torch.Size([256])\n",
      "layer1.2.bn3.bias \t torch.Size([256])\n",
      "layer1.2.bn3.running_mean \t torch.Size([256])\n",
      "layer1.2.bn3.running_var \t torch.Size([256])\n",
      "layer1.2.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer2.0.conv1.weight \t torch.Size([128, 256, 1, 1])\n",
      "layer2.0.bn1.weight \t torch.Size([128])\n",
      "layer2.0.bn1.bias \t torch.Size([128])\n",
      "layer2.0.bn1.running_mean \t torch.Size([128])\n",
      "layer2.0.bn1.running_var \t torch.Size([128])\n",
      "layer2.0.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer2.0.conv2.weight \t torch.Size([128, 128, 3, 3])\n",
      "layer2.0.bn2.weight \t torch.Size([128])\n",
      "layer2.0.bn2.bias \t torch.Size([128])\n",
      "layer2.0.bn2.running_mean \t torch.Size([128])\n",
      "layer2.0.bn2.running_var \t torch.Size([128])\n",
      "layer2.0.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer2.0.conv3.weight \t torch.Size([512, 128, 1, 1])\n",
      "layer2.0.bn3.weight \t torch.Size([512])\n",
      "layer2.0.bn3.bias \t torch.Size([512])\n",
      "layer2.0.bn3.running_mean \t torch.Size([512])\n",
      "layer2.0.bn3.running_var \t torch.Size([512])\n",
      "layer2.0.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer2.0.downsample.0.weight \t torch.Size([512, 256, 1, 1])\n",
      "layer2.0.downsample.1.weight \t torch.Size([512])\n",
      "layer2.0.downsample.1.bias \t torch.Size([512])\n",
      "layer2.0.downsample.1.running_mean \t torch.Size([512])\n",
      "layer2.0.downsample.1.running_var \t torch.Size([512])\n",
      "layer2.0.downsample.1.num_batches_tracked \t torch.Size([])\n",
      "layer2.1.conv1.weight \t torch.Size([128, 512, 1, 1])\n",
      "layer2.1.bn1.weight \t torch.Size([128])\n",
      "layer2.1.bn1.bias \t torch.Size([128])\n",
      "layer2.1.bn1.running_mean \t torch.Size([128])\n",
      "layer2.1.bn1.running_var \t torch.Size([128])\n",
      "layer2.1.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer2.1.conv2.weight \t torch.Size([128, 128, 3, 3])\n",
      "layer2.1.bn2.weight \t torch.Size([128])\n",
      "layer2.1.bn2.bias \t torch.Size([128])\n",
      "layer2.1.bn2.running_mean \t torch.Size([128])\n",
      "layer2.1.bn2.running_var \t torch.Size([128])\n",
      "layer2.1.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer2.1.conv3.weight \t torch.Size([512, 128, 1, 1])\n",
      "layer2.1.bn3.weight \t torch.Size([512])\n",
      "layer2.1.bn3.bias \t torch.Size([512])\n",
      "layer2.1.bn3.running_mean \t torch.Size([512])\n",
      "layer2.1.bn3.running_var \t torch.Size([512])\n",
      "layer2.1.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer2.2.conv1.weight \t torch.Size([128, 512, 1, 1])\n",
      "layer2.2.bn1.weight \t torch.Size([128])\n",
      "layer2.2.bn1.bias \t torch.Size([128])\n",
      "layer2.2.bn1.running_mean \t torch.Size([128])\n",
      "layer2.2.bn1.running_var \t torch.Size([128])\n",
      "layer2.2.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer2.2.conv2.weight \t torch.Size([128, 128, 3, 3])\n",
      "layer2.2.bn2.weight \t torch.Size([128])\n",
      "layer2.2.bn2.bias \t torch.Size([128])\n",
      "layer2.2.bn2.running_mean \t torch.Size([128])\n",
      "layer2.2.bn2.running_var \t torch.Size([128])\n",
      "layer2.2.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer2.2.conv3.weight \t torch.Size([512, 128, 1, 1])\n",
      "layer2.2.bn3.weight \t torch.Size([512])\n",
      "layer2.2.bn3.bias \t torch.Size([512])\n",
      "layer2.2.bn3.running_mean \t torch.Size([512])\n",
      "layer2.2.bn3.running_var \t torch.Size([512])\n",
      "layer2.2.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer2.3.conv1.weight \t torch.Size([128, 512, 1, 1])\n",
      "layer2.3.bn1.weight \t torch.Size([128])\n",
      "layer2.3.bn1.bias \t torch.Size([128])\n",
      "layer2.3.bn1.running_mean \t torch.Size([128])\n",
      "layer2.3.bn1.running_var \t torch.Size([128])\n",
      "layer2.3.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer2.3.conv2.weight \t torch.Size([128, 128, 3, 3])\n",
      "layer2.3.bn2.weight \t torch.Size([128])\n",
      "layer2.3.bn2.bias \t torch.Size([128])\n",
      "layer2.3.bn2.running_mean \t torch.Size([128])\n",
      "layer2.3.bn2.running_var \t torch.Size([128])\n",
      "layer2.3.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer2.3.conv3.weight \t torch.Size([512, 128, 1, 1])\n",
      "layer2.3.bn3.weight \t torch.Size([512])\n",
      "layer2.3.bn3.bias \t torch.Size([512])\n",
      "layer2.3.bn3.running_mean \t torch.Size([512])\n",
      "layer2.3.bn3.running_var \t torch.Size([512])\n",
      "layer2.3.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer3.0.conv1.weight \t torch.Size([256, 512, 1, 1])\n",
      "layer3.0.bn1.weight \t torch.Size([256])\n",
      "layer3.0.bn1.bias \t torch.Size([256])\n",
      "layer3.0.bn1.running_mean \t torch.Size([256])\n",
      "layer3.0.bn1.running_var \t torch.Size([256])\n",
      "layer3.0.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer3.0.conv2.weight \t torch.Size([256, 256, 3, 3])\n",
      "layer3.0.bn2.weight \t torch.Size([256])\n",
      "layer3.0.bn2.bias \t torch.Size([256])\n",
      "layer3.0.bn2.running_mean \t torch.Size([256])\n",
      "layer3.0.bn2.running_var \t torch.Size([256])\n",
      "layer3.0.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer3.0.conv3.weight \t torch.Size([1024, 256, 1, 1])\n",
      "layer3.0.bn3.weight \t torch.Size([1024])\n",
      "layer3.0.bn3.bias \t torch.Size([1024])\n",
      "layer3.0.bn3.running_mean \t torch.Size([1024])\n",
      "layer3.0.bn3.running_var \t torch.Size([1024])\n",
      "layer3.0.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer3.0.downsample.0.weight \t torch.Size([1024, 512, 1, 1])\n",
      "layer3.0.downsample.1.weight \t torch.Size([1024])\n",
      "layer3.0.downsample.1.bias \t torch.Size([1024])\n",
      "layer3.0.downsample.1.running_mean \t torch.Size([1024])\n",
      "layer3.0.downsample.1.running_var \t torch.Size([1024])\n",
      "layer3.0.downsample.1.num_batches_tracked \t torch.Size([])\n",
      "layer3.1.conv1.weight \t torch.Size([256, 1024, 1, 1])\n",
      "layer3.1.bn1.weight \t torch.Size([256])\n",
      "layer3.1.bn1.bias \t torch.Size([256])\n",
      "layer3.1.bn1.running_mean \t torch.Size([256])\n",
      "layer3.1.bn1.running_var \t torch.Size([256])\n",
      "layer3.1.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer3.1.conv2.weight \t torch.Size([256, 256, 3, 3])\n",
      "layer3.1.bn2.weight \t torch.Size([256])\n",
      "layer3.1.bn2.bias \t torch.Size([256])\n",
      "layer3.1.bn2.running_mean \t torch.Size([256])\n",
      "layer3.1.bn2.running_var \t torch.Size([256])\n",
      "layer3.1.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer3.1.conv3.weight \t torch.Size([1024, 256, 1, 1])\n",
      "layer3.1.bn3.weight \t torch.Size([1024])\n",
      "layer3.1.bn3.bias \t torch.Size([1024])\n",
      "layer3.1.bn3.running_mean \t torch.Size([1024])\n",
      "layer3.1.bn3.running_var \t torch.Size([1024])\n",
      "layer3.1.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer3.2.conv1.weight \t torch.Size([256, 1024, 1, 1])\n",
      "layer3.2.bn1.weight \t torch.Size([256])\n",
      "layer3.2.bn1.bias \t torch.Size([256])\n",
      "layer3.2.bn1.running_mean \t torch.Size([256])\n",
      "layer3.2.bn1.running_var \t torch.Size([256])\n",
      "layer3.2.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer3.2.conv2.weight \t torch.Size([256, 256, 3, 3])\n",
      "layer3.2.bn2.weight \t torch.Size([256])\n",
      "layer3.2.bn2.bias \t torch.Size([256])\n",
      "layer3.2.bn2.running_mean \t torch.Size([256])\n",
      "layer3.2.bn2.running_var \t torch.Size([256])\n",
      "layer3.2.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer3.2.conv3.weight \t torch.Size([1024, 256, 1, 1])\n",
      "layer3.2.bn3.weight \t torch.Size([1024])\n",
      "layer3.2.bn3.bias \t torch.Size([1024])\n",
      "layer3.2.bn3.running_mean \t torch.Size([1024])\n",
      "layer3.2.bn3.running_var \t torch.Size([1024])\n",
      "layer3.2.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer3.3.conv1.weight \t torch.Size([256, 1024, 1, 1])\n",
      "layer3.3.bn1.weight \t torch.Size([256])\n",
      "layer3.3.bn1.bias \t torch.Size([256])\n",
      "layer3.3.bn1.running_mean \t torch.Size([256])\n",
      "layer3.3.bn1.running_var \t torch.Size([256])\n",
      "layer3.3.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer3.3.conv2.weight \t torch.Size([256, 256, 3, 3])\n",
      "layer3.3.bn2.weight \t torch.Size([256])\n",
      "layer3.3.bn2.bias \t torch.Size([256])\n",
      "layer3.3.bn2.running_mean \t torch.Size([256])\n",
      "layer3.3.bn2.running_var \t torch.Size([256])\n",
      "layer3.3.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer3.3.conv3.weight \t torch.Size([1024, 256, 1, 1])\n",
      "layer3.3.bn3.weight \t torch.Size([1024])\n",
      "layer3.3.bn3.bias \t torch.Size([1024])\n",
      "layer3.3.bn3.running_mean \t torch.Size([1024])\n",
      "layer3.3.bn3.running_var \t torch.Size([1024])\n",
      "layer3.3.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer3.4.conv1.weight \t torch.Size([256, 1024, 1, 1])\n",
      "layer3.4.bn1.weight \t torch.Size([256])\n",
      "layer3.4.bn1.bias \t torch.Size([256])\n",
      "layer3.4.bn1.running_mean \t torch.Size([256])\n",
      "layer3.4.bn1.running_var \t torch.Size([256])\n",
      "layer3.4.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer3.4.conv2.weight \t torch.Size([256, 256, 3, 3])\n",
      "layer3.4.bn2.weight \t torch.Size([256])\n",
      "layer3.4.bn2.bias \t torch.Size([256])\n",
      "layer3.4.bn2.running_mean \t torch.Size([256])\n",
      "layer3.4.bn2.running_var \t torch.Size([256])\n",
      "layer3.4.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer3.4.conv3.weight \t torch.Size([1024, 256, 1, 1])\n",
      "layer3.4.bn3.weight \t torch.Size([1024])\n",
      "layer3.4.bn3.bias \t torch.Size([1024])\n",
      "layer3.4.bn3.running_mean \t torch.Size([1024])\n",
      "layer3.4.bn3.running_var \t torch.Size([1024])\n",
      "layer3.4.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer3.5.conv1.weight \t torch.Size([256, 1024, 1, 1])\n",
      "layer3.5.bn1.weight \t torch.Size([256])\n",
      "layer3.5.bn1.bias \t torch.Size([256])\n",
      "layer3.5.bn1.running_mean \t torch.Size([256])\n",
      "layer3.5.bn1.running_var \t torch.Size([256])\n",
      "layer3.5.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer3.5.conv2.weight \t torch.Size([256, 256, 3, 3])\n",
      "layer3.5.bn2.weight \t torch.Size([256])\n",
      "layer3.5.bn2.bias \t torch.Size([256])\n",
      "layer3.5.bn2.running_mean \t torch.Size([256])\n",
      "layer3.5.bn2.running_var \t torch.Size([256])\n",
      "layer3.5.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer3.5.conv3.weight \t torch.Size([1024, 256, 1, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer3.5.bn3.weight \t torch.Size([1024])\n",
      "layer3.5.bn3.bias \t torch.Size([1024])\n",
      "layer3.5.bn3.running_mean \t torch.Size([1024])\n",
      "layer3.5.bn3.running_var \t torch.Size([1024])\n",
      "layer3.5.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer4.0.conv1.weight \t torch.Size([512, 1024, 1, 1])\n",
      "layer4.0.bn1.weight \t torch.Size([512])\n",
      "layer4.0.bn1.bias \t torch.Size([512])\n",
      "layer4.0.bn1.running_mean \t torch.Size([512])\n",
      "layer4.0.bn1.running_var \t torch.Size([512])\n",
      "layer4.0.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer4.0.conv2.weight \t torch.Size([512, 512, 3, 3])\n",
      "layer4.0.bn2.weight \t torch.Size([512])\n",
      "layer4.0.bn2.bias \t torch.Size([512])\n",
      "layer4.0.bn2.running_mean \t torch.Size([512])\n",
      "layer4.0.bn2.running_var \t torch.Size([512])\n",
      "layer4.0.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer4.0.conv3.weight \t torch.Size([2048, 512, 1, 1])\n",
      "layer4.0.bn3.weight \t torch.Size([2048])\n",
      "layer4.0.bn3.bias \t torch.Size([2048])\n",
      "layer4.0.bn3.running_mean \t torch.Size([2048])\n",
      "layer4.0.bn3.running_var \t torch.Size([2048])\n",
      "layer4.0.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer4.0.downsample.0.weight \t torch.Size([2048, 1024, 1, 1])\n",
      "layer4.0.downsample.1.weight \t torch.Size([2048])\n",
      "layer4.0.downsample.1.bias \t torch.Size([2048])\n",
      "layer4.0.downsample.1.running_mean \t torch.Size([2048])\n",
      "layer4.0.downsample.1.running_var \t torch.Size([2048])\n",
      "layer4.0.downsample.1.num_batches_tracked \t torch.Size([])\n",
      "layer4.1.conv1.weight \t torch.Size([512, 2048, 1, 1])\n",
      "layer4.1.bn1.weight \t torch.Size([512])\n",
      "layer4.1.bn1.bias \t torch.Size([512])\n",
      "layer4.1.bn1.running_mean \t torch.Size([512])\n",
      "layer4.1.bn1.running_var \t torch.Size([512])\n",
      "layer4.1.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer4.1.conv2.weight \t torch.Size([512, 512, 3, 3])\n",
      "layer4.1.bn2.weight \t torch.Size([512])\n",
      "layer4.1.bn2.bias \t torch.Size([512])\n",
      "layer4.1.bn2.running_mean \t torch.Size([512])\n",
      "layer4.1.bn2.running_var \t torch.Size([512])\n",
      "layer4.1.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer4.1.conv3.weight \t torch.Size([2048, 512, 1, 1])\n",
      "layer4.1.bn3.weight \t torch.Size([2048])\n",
      "layer4.1.bn3.bias \t torch.Size([2048])\n",
      "layer4.1.bn3.running_mean \t torch.Size([2048])\n",
      "layer4.1.bn3.running_var \t torch.Size([2048])\n",
      "layer4.1.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer4.2.conv1.weight \t torch.Size([512, 2048, 1, 1])\n",
      "layer4.2.bn1.weight \t torch.Size([512])\n",
      "layer4.2.bn1.bias \t torch.Size([512])\n",
      "layer4.2.bn1.running_mean \t torch.Size([512])\n",
      "layer4.2.bn1.running_var \t torch.Size([512])\n",
      "layer4.2.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer4.2.conv2.weight \t torch.Size([512, 512, 3, 3])\n",
      "layer4.2.bn2.weight \t torch.Size([512])\n",
      "layer4.2.bn2.bias \t torch.Size([512])\n",
      "layer4.2.bn2.running_mean \t torch.Size([512])\n",
      "layer4.2.bn2.running_var \t torch.Size([512])\n",
      "layer4.2.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer4.2.conv3.weight \t torch.Size([2048, 512, 1, 1])\n",
      "layer4.2.bn3.weight \t torch.Size([2048])\n",
      "layer4.2.bn3.bias \t torch.Size([2048])\n",
      "layer4.2.bn3.running_mean \t torch.Size([2048])\n",
      "layer4.2.bn3.running_var \t torch.Size([2048])\n",
      "layer4.2.bn3.num_batches_tracked \t torch.Size([])\n",
      "fc.weight \t torch.Size([120, 2048])\n",
      "fc.bias \t torch.Size([120])\n"
     ]
    }
   ],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [2552374102280, 2552374101240]}]\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validate Model\n",
    "\n",
    "def train_model(loader, model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    \n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    history  = {\n",
    "        'train_acc': [],\n",
    "        'train_los': [],\n",
    "        'valid_acc': [],\n",
    "        'valid_los': []\n",
    "    }\n",
    "    \n",
    "    dataset_sizes = {\n",
    "        'train': len(loader['train'].dataset),\n",
    "        'valid': len(loader['valid'].dataset)\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        for phase in ['train', 'valid']:\n",
    "            \n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "            \n",
    "            for inputs, labels, iids in loader[phase]:\n",
    "                if use_gpu:\n",
    "                    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs.data, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # statistic\n",
    "                running_loss += loss.item()\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            \n",
    "            data_size = dataset_sizes[phase]\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_epoch_loss = running_loss / data_size\n",
    "                train_epoch_acc  = running_corrects / data_size\n",
    "            else:\n",
    "                valid_epoch_loss = running_loss / data_size\n",
    "                valid_epoch_acc  = running_corrects / data_size\n",
    "\n",
    "            if phase == 'valid' and valid_epoch_acc > best_acc:\n",
    "                best_acc = valid_epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        history['train_acc'].append(train_epoch_acc.item())\n",
    "        history['train_los'].append(train_epoch_loss)\n",
    "        history['valid_acc'].append(valid_epoch_acc.item())\n",
    "        history['valid_los'].append(valid_epoch_loss)\n",
    "        \n",
    "        fmt_str = (\n",
    "            'Epoch [{:3d}/{:3d}] train loss: {:.4f} acc: {:.4f}'\n",
    "            ', valid loss: {:.4f} acc: {:.4f}'\n",
    "        )\n",
    "        print(fmt_str.format(\n",
    "            epoch, num_epochs - 1, \n",
    "            train_epoch_loss, train_epoch_acc, valid_epoch_loss, valid_epoch_acc\n",
    "        ))\n",
    "\n",
    "    print('\\nBest val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_acc, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  0/  2] train loss: 0.2223 acc: 0.3494, valid loss: 0.1329 acc: 0.6655\n",
      "Epoch [  1/  2] train loss: 0.1199 acc: 0.6863, valid loss: 0.0744 acc: 0.7971\n"
     ]
    }
   ],
   "source": [
    "NumEpochs = 3\n",
    "start_time = time.time()\n",
    "\n",
    "best_model, best_acc, history = train_model(\n",
    "    dataLoader, model, criterion, optimizer, exp_lr_scheduler, NumEpochs\n",
    ")\n",
    "    \n",
    "print('Training time: {:10f} minutes'.format((time.time()-start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(history, indent=2)\n",
    "\n",
    "train_acc = history['train_acc']\n",
    "train_los = history['train_los']\n",
    "valid_acc = history['valid_acc']\n",
    "valid_los = history['valid_los']\n",
    "\n",
    "# for i in range(len(history)):\n",
    "#     train_acc.append(history[i]['train_acc'])\n",
    "#     train_los.append(history[i]['train_loss'])\n",
    "#     valid_acc.append(history[i]['valid_acc'])\n",
    "#     valid_los.append(history[i]['valid_loss'])\n",
    "        \n",
    "def plot_lines(y1, y2, label=None, ax=None):\n",
    "    epochs = len(y1)\n",
    "    x = np.linspace(0, epochs, num=epochs)\n",
    "    ax.plot(x, y1, label=\"acc\")\n",
    "    ax.plot(x, y2, label=\"loss\")\n",
    "    # ax.set_title('training v.s. validate')\n",
    "    ax.set_title(label)\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Percentage')\n",
    "    \n",
    "    \n",
    "# 1. Plot in same line, this would work\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "plot_lines(train_acc, train_los, 'training', ax1)\n",
    "plt.legend()\n",
    "\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "plot_lines(valid_acc, valid_los, 'validate', ax2)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currDT = datetime.now()\n",
    "currStr = currDT.strftime(\"%Y%m%d-%H%M\")\n",
    "\n",
    "acc_str = int(best_acc * 100)\n",
    "fname_best_model = 'resnet50_{}_acc{}.pth'.format(currStr, acc_str)\n",
    "\n",
    "best_model_wts = best_model.state_dict()\n",
    "\n",
    "OutPath = Params['OutPath']\n",
    "best_model_out = join(OutPath, fname_best_model)\n",
    "\n",
    "torch.save(best_model_wts, best_model_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save parameters to json file\n",
    "\n",
    "fname = 'Params_{}.json'.format(currStr)\n",
    "f_abspath = join(OutPath, fname)\n",
    "\n",
    "json_str = json.dumps(Params, indent=4)\n",
    "print(json_str)\n",
    "\n",
    "with open(f_abspath, 'w') as fout:\n",
    "    fout.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save breed dict to json file\n",
    "fname = 'BreedDict_{}.json'.format(currStr)\n",
    "f_abspath = join(OutPath, fname)\n",
    "\n",
    "json_str = json.dumps(dict_bid_fw, indent=4)\n",
    "print(json_str)\n",
    "\n",
    "with open(f_abspath, 'w') as fout:\n",
    "    fout.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
