{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.5.1\n",
      "Torchvision Version:  0.6.1\n"
     ]
    }
   ],
   "source": [
    "# From: https://www.kaggle.com/c/dog-breed-identification/data\n",
    "# Author: Morpheus Hsieh (morpheus.hsieh@gmail.com)\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import os, sys\n",
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "from os import listdir\n",
    "from os.path import join, exists\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "{\n",
      "  'DataPath'    : 'D:\\GitWork\\dog_breed\\data',\n",
      "  'OutPath'     : 'D:\\GitWork\\dog_breed\\output',\n",
      "  'ProcPath'    : 'D:\\GitWork\\dog_breed\\processed',\n",
      "  'PreTrainPath': 'D:\\GitWork\\dog_breed\\pretrained',\n",
      "  'PreTrainFile': 'resnet50_20200923-1604_acc79.pth',\n",
      "  'LoadPreModel': True,\n",
      "  'TestPath'    : 'D:\\GitWork\\dog_breed\\data\\test',\n",
      "  'TrainPath'   : 'D:\\GitWork\\dog_breed\\data\\train',\n",
      "  'CsvLabel'    : 'labels.csv',\n",
      "  'BatchSize'   : 16,\n",
      "  'FracForTrain': 0.8\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "Params = {\n",
    "    'DataPath'    : r'D:\\GitWork\\dog_breed\\data',\n",
    "    'OutPath'     : r'D:\\GitWork\\dog_breed\\output',\n",
    "    'ProcPath'    : r'D:\\GitWork\\dog_breed\\processed',\n",
    "    'PreTrainPath': r'D:\\GitWork\\dog_breed\\pretrained',\n",
    "    'PreTrainFile': 'resnet50_20200923-1604_acc79.pth',\n",
    "    'LoadPreModel': True,\n",
    "    'TestPath'    : r'D:\\GitWork\\dog_breed\\data\\test',\n",
    "    'TrainPath'   : r'D:\\GitWork\\dog_breed\\data\\train',\n",
    "    'CsvLabel'    : 'labels.csv',\n",
    "    'BatchSize'   : 16,\n",
    "    'FracForTrain': 0.8\n",
    "}\n",
    "\n",
    "\n",
    "def prettyDict(dic, indent=2):\n",
    "    array = []\n",
    "    key_maxlen = 0\n",
    "    item_cnt = 0\n",
    "    item_size = len(dic)\n",
    "    split_str = ': '\n",
    "    \n",
    "    for key, val in dic.items():\n",
    "        if key_maxlen < len(str(key)): \n",
    "            key_maxlen = len(str(key))\n",
    "        \n",
    "        tmpstr = ''\n",
    "        tmpstr += f\"'{key}'\" if isinstance(key, str) else f\"{key}\"\n",
    "        tmpstr += split_str\n",
    "        tmpstr += f\"'{val}'\" if isinstance(val, str) else f\"{val}\"\n",
    "\n",
    "        item_cnt += 1\n",
    "        if item_cnt < item_size: tmpstr += ','\n",
    "        array.append(tmpstr)\n",
    "    \n",
    "    for i in range(len(array)):\n",
    "        inStr = array[i]\n",
    "        ary = inStr.split(split_str)\n",
    "        key = ary[0].ljust(key_maxlen+2)\n",
    "        val = ary[1]\n",
    "        array[i] = (' '*indent) + key + ': ' + val\n",
    "        \n",
    "    outstr = '{\\n' + '\\n'.join(array) + '\\n}'\n",
    "    return outstr\n",
    "\n",
    "outstr = prettyDict(Params)\n",
    "print('Parameters:')\n",
    "print(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10222 entries, 0 to 10221\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      10222 non-null  object\n",
      " 1   breed   10222 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 159.8+ KB\n",
      "None\n",
      "\n",
      "                                 id             breed\n",
      "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
      "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
      "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
      "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
      "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever\n"
     ]
    }
   ],
   "source": [
    "# Read breed information from csv\n",
    "DataPath = Params.get('DataPath')\n",
    "csv_labels = Params.get('CsvLabel')\n",
    "f_abspath = join(DataPath, csv_labels)\n",
    "\n",
    "df_labels = pd.read_csv(f_abspath)\n",
    "\n",
    "print(df_labels.info())\n",
    "print()\n",
    "print(df_labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120 entries, 0 to 119\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   breed_id  120 non-null    int64 \n",
      " 1   breed     120 non-null    object\n",
      " 2   count     120 non-null    int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 2.9+ KB\n",
      "None\n",
      "\n",
      "   breed_id                 breed  count\n",
      "0         0    scottish_deerhound    126\n",
      "1         1           maltese_dog    117\n",
      "2         2          afghan_hound    116\n",
      "3         3           entlebucher    115\n",
      "4         4  bernese_mountain_dog    114\n",
      "\n",
      "Num classes: 120\n"
     ]
    }
   ],
   "source": [
    "# Count all breeds\n",
    "def countBreeds(df):\n",
    "    df1 = df_labels.groupby(\"breed\")[\"id\"].count().reset_index(name=\"count\")\n",
    "    df1 = df1.sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "    df1.insert(0, 'breed_id', df1.index)\n",
    "    return df1\n",
    "\n",
    "df_breeds = countBreeds(df_labels)\n",
    "print(df_breeds.info())\n",
    "print()\n",
    "print(df_breeds.head())\n",
    "\n",
    "NumClasses = int(df_breeds.shape[0])\n",
    "print('\\nNum classes:', NumClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10222 entries, 0 to 10221\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   image     10222 non-null  object\n",
      " 1   breed_id  10222 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 159.8+ KB\n",
      "None\n",
      "                                               image  breed_id\n",
      "0  D:\\GitWork\\dog_breed\\data\\train\\000bec180eb18c...        42\n",
      "1  D:\\GitWork\\dog_breed\\data\\train\\001513dfcb2ffa...        72\n",
      "2  D:\\GitWork\\dog_breed\\data\\train\\001cdf01b096e0...        94\n",
      "3  D:\\GitWork\\dog_breed\\data\\train\\00214f311d5d22...        50\n",
      "4  D:\\GitWork\\dog_breed\\data\\train\\0021f9ceb3235e...       115\n"
     ]
    }
   ],
   "source": [
    "# Process labels\n",
    "\n",
    "dict_bid_fw = dict(df_breeds[['breed', 'breed_id']].values)\n",
    "# print(dict_bid_fw)\n",
    "\n",
    "dict_bid_bw = dict(df_breeds[['breed_id', 'breed']].values)\n",
    "# print(dict_bid_bw)\n",
    "\n",
    "# Build processed labels file\n",
    "df_data = pd.DataFrame(columns=['image', 'breed_id'])\n",
    "df_data['breed_id'] = df_labels.breed.map(dict_bid_fw)\n",
    "\n",
    "TranPath = Params['TrainPath']\n",
    "\n",
    "df_data['image'] = df_labels.apply (\n",
    "    lambda row: join(TranPath, row['id']+'.jpg') \\\n",
    "    if exists(join(TranPath, row['id']+'.jpg')) else None, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(df_data.info())\n",
    "print(df_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSet size: {'train': 8177, 'valid': 2045}\n",
      "\n",
      "Image shape: torch.Size([16, 3, 224, 224])\n",
      "Label shape: torch.Size([16])\n",
      "\n",
      "Image iid:\n",
      "  9e14a1584d8ee8447ff5f71896fca8a8\n",
      "  0c68a578981993b919e89c611f04a97f\n",
      "  caf49640a8436f3ed39c56b1c5e447db\n",
      "  776a702e80fc75c7969198ede3ee0aad\n",
      "  757556f1f0520020f09adea9512078a7\n",
      "  87e198d332493454d0c5645945050f8e\n",
      "  0a7899ed6a15f4af8f28e01c9c44dcfe\n",
      "  8e45f42d744b4a48ffe7ea8520a96f65\n",
      "  1935abc5226ad6d2cdcaed722d685623\n",
      "  b51261d75a427148d502ecd9108312db\n",
      "  9529b8093aeca32d8828004347667c44\n",
      "  b6fe6d1a08a8766f5db00a06e635bbc2\n",
      "  07096719a671e1737b829bd1a88f1dbf\n",
      "  373cc94717c239adb17c67421fa6d73a\n",
      "  5783b64ce4c041c603e436f27e9c7e4c\n",
      "  670b1a17892480ae3cbc151f3030f14f\n",
      "\n",
      "Image shape: torch.Size([3, 224, 224])\n",
      "\n",
      "tensor([[[-1.5528, -1.4500, -1.5185,  ..., -1.2103, -1.2959, -1.3302],\n",
      "         [-1.6384, -1.5185, -1.4672,  ..., -1.3302, -1.3644, -1.3987],\n",
      "         [-1.6213, -1.5014, -1.3987,  ..., -1.3987, -1.4158, -1.4158],\n",
      "         ...,\n",
      "         [-1.4500, -1.3473, -1.1247,  ..., -1.5699, -1.5528, -1.5185],\n",
      "         [-1.4158, -1.3302, -1.1589,  ..., -1.5357, -1.5528, -1.5185],\n",
      "         [-1.4329, -1.3473, -1.1247,  ..., -1.5357, -1.5357, -1.5014]],\n",
      "\n",
      "        [[-1.3529, -1.2129, -1.2479,  ..., -1.2654, -1.3529, -1.3880],\n",
      "         [-1.4405, -1.2829, -1.1779,  ..., -1.3880, -1.4230, -1.4580],\n",
      "         [-1.4055, -1.2654, -1.1253,  ..., -1.4580, -1.4755, -1.4755],\n",
      "         ...,\n",
      "         [-1.4405, -1.3704, -1.1954,  ..., -1.6331, -1.6155, -1.5805],\n",
      "         [-1.4055, -1.3529, -1.2129,  ..., -1.5980, -1.6155, -1.5805],\n",
      "         [-1.4230, -1.3704, -1.1954,  ..., -1.5980, -1.5980, -1.5630]],\n",
      "\n",
      "        [[-1.1247, -0.9678, -0.9853,  ..., -1.1247, -1.2119, -1.2467],\n",
      "         [-1.2119, -1.0376, -0.9156,  ..., -1.2467, -1.2816, -1.3164],\n",
      "         [-1.1770, -1.0201, -0.8633,  ..., -1.3164, -1.3339, -1.3339],\n",
      "         ...,\n",
      "         [-1.2816, -1.2467, -1.0898,  ..., -1.5604, -1.5430, -1.5081],\n",
      "         [-1.2816, -1.2293, -1.0724,  ..., -1.5256, -1.5430, -1.5081],\n",
      "         [-1.2990, -1.2467, -1.0550,  ..., -1.5256, -1.5256, -1.4907]]])\n",
      "\n",
      "Labels: tensor(76)\n"
     ]
    }
   ],
   "source": [
    "# Create dataset\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean = [0.485, 0.456, 0.406],\n",
    "        std  = [0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "class myDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, phase='train', frac=0.8, transform=None):\n",
    "        \n",
    "        num_rows = df.shape[0]\n",
    "        train_len = int(float(frac) * float(num_rows))\n",
    "        valid_len = num_rows - train_len\n",
    "        \n",
    "        data = df.head(train_len) if phase=='train' else df.tail(valid_len)\n",
    "        self.images = data['image'].tolist()\n",
    "        self.labels = data['breed_id'].tolist()\n",
    "\n",
    "        self.transform = transform\n",
    "        self.len = len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        f_abspath = self.images[index]\n",
    "        img_pil = Image.open(f_abspath)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img_pil)\n",
    "\n",
    "        lbl = int(self.labels[index])\n",
    "        iid = os.path.split(f_abspath)[1].replace('.jpg', '')\n",
    "        \n",
    "        return [img, lbl, iid]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "\n",
    "frac = Params['FracForTrain']\n",
    "\n",
    "phases = ['train', 'valid']\n",
    "dataSet = { \n",
    "    x: myDataset(df_data, phase=x, frac=frac, transform=transform) for x in phases \n",
    "}\n",
    "\n",
    "BatchSize = Params['BatchSize']\n",
    "dataLoader = {\n",
    "    x: DataLoader(dataSet[x], batch_size=BatchSize, shuffle=True) for x in phases\n",
    "}\n",
    "\n",
    "dataSizes = { x: len(dataSet[x]) for x in phases }\n",
    "print('DataSet size:', dataSizes)\n",
    "\n",
    "trainLoader = dataLoader['train']\n",
    "imgs, lbls, iids = next(iter(trainLoader))\n",
    "print('\\nImage shape:', imgs.size())\n",
    "print('Label shape:', lbls.size())\n",
    "\n",
    "print('\\nImage iid:')\n",
    "id_list = [''.join(iid) for iid in iids]\n",
    "print('  '+'\\n  '.join(id_list))\n",
    "\n",
    "img = imgs[0]\n",
    "print('\\nImage shape:', img.shape)\n",
    "print(); print(img)\n",
    "\n",
    "print('\\nLabels:', lbls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Use GPU for train\n",
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=120, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Build Model\n",
    "def buildModel(use_gpu, numClasses, preTrainModel=None):\n",
    "    model = models.resnet50(pretrained=True)\n",
    "\n",
    "    # freeze all model parameters\n",
    "    for param in model.parameters():\n",
    "        model.requires_grad = False\n",
    "\n",
    "    # new final layer with 16 classes\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, numClasses)\n",
    "    \n",
    "    if preTrainModel is not None:\n",
    "        model.load_state_dict(preTrainModel)\n",
    "        \n",
    "    if use_gpu: \n",
    "        model = model.cuda()\n",
    "        \n",
    "    return model\n",
    "\n",
    "\n",
    "pretrain_model = None\n",
    "\n",
    "load_premodel = Params['LoadPreModel']\n",
    "if load_premodel > 0:\n",
    "    path  = Params['PreTrainPath']\n",
    "    fname = Params['PreTrainFile']\n",
    "    pretrain_model = torch.load(join(path, fname))\n",
    "\n",
    "model = buildModel(use_gpu, NumClasses, preTrainModel=pretrain_model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "conv1.weight \t torch.Size([64, 3, 7, 7])\n",
      "bn1.weight \t torch.Size([64])\n",
      "bn1.bias \t torch.Size([64])\n",
      "bn1.running_mean \t torch.Size([64])\n",
      "bn1.running_var \t torch.Size([64])\n",
      "bn1.num_batches_tracked \t torch.Size([])\n",
      "layer1.0.conv1.weight \t torch.Size([64, 64, 1, 1])\n",
      "layer1.0.bn1.weight \t torch.Size([64])\n",
      "layer1.0.bn1.bias \t torch.Size([64])\n",
      "layer1.0.bn1.running_mean \t torch.Size([64])\n",
      "layer1.0.bn1.running_var \t torch.Size([64])\n",
      "layer1.0.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer1.0.conv2.weight \t torch.Size([64, 64, 3, 3])\n",
      "layer1.0.bn2.weight \t torch.Size([64])\n",
      "layer1.0.bn2.bias \t torch.Size([64])\n",
      "layer1.0.bn2.running_mean \t torch.Size([64])\n",
      "layer1.0.bn2.running_var \t torch.Size([64])\n",
      "layer1.0.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer1.0.conv3.weight \t torch.Size([256, 64, 1, 1])\n",
      "layer1.0.bn3.weight \t torch.Size([256])\n",
      "layer1.0.bn3.bias \t torch.Size([256])\n",
      "layer1.0.bn3.running_mean \t torch.Size([256])\n",
      "layer1.0.bn3.running_var \t torch.Size([256])\n",
      "layer1.0.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer1.0.downsample.0.weight \t torch.Size([256, 64, 1, 1])\n",
      "layer1.0.downsample.1.weight \t torch.Size([256])\n",
      "layer1.0.downsample.1.bias \t torch.Size([256])\n",
      "layer1.0.downsample.1.running_mean \t torch.Size([256])\n",
      "layer1.0.downsample.1.running_var \t torch.Size([256])\n",
      "layer1.0.downsample.1.num_batches_tracked \t torch.Size([])\n",
      "layer1.1.conv1.weight \t torch.Size([64, 256, 1, 1])\n",
      "layer1.1.bn1.weight \t torch.Size([64])\n",
      "layer1.1.bn1.bias \t torch.Size([64])\n",
      "layer1.1.bn1.running_mean \t torch.Size([64])\n",
      "layer1.1.bn1.running_var \t torch.Size([64])\n",
      "layer1.1.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer1.1.conv2.weight \t torch.Size([64, 64, 3, 3])\n",
      "layer1.1.bn2.weight \t torch.Size([64])\n",
      "layer1.1.bn2.bias \t torch.Size([64])\n",
      "layer1.1.bn2.running_mean \t torch.Size([64])\n",
      "layer1.1.bn2.running_var \t torch.Size([64])\n",
      "layer1.1.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer1.1.conv3.weight \t torch.Size([256, 64, 1, 1])\n",
      "layer1.1.bn3.weight \t torch.Size([256])\n",
      "layer1.1.bn3.bias \t torch.Size([256])\n",
      "layer1.1.bn3.running_mean \t torch.Size([256])\n",
      "layer1.1.bn3.running_var \t torch.Size([256])\n",
      "layer1.1.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer1.2.conv1.weight \t torch.Size([64, 256, 1, 1])\n",
      "layer1.2.bn1.weight \t torch.Size([64])\n",
      "layer1.2.bn1.bias \t torch.Size([64])\n",
      "layer1.2.bn1.running_mean \t torch.Size([64])\n",
      "layer1.2.bn1.running_var \t torch.Size([64])\n",
      "layer1.2.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer1.2.conv2.weight \t torch.Size([64, 64, 3, 3])\n",
      "layer1.2.bn2.weight \t torch.Size([64])\n",
      "layer1.2.bn2.bias \t torch.Size([64])\n",
      "layer1.2.bn2.running_mean \t torch.Size([64])\n",
      "layer1.2.bn2.running_var \t torch.Size([64])\n",
      "layer1.2.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer1.2.conv3.weight \t torch.Size([256, 64, 1, 1])\n",
      "layer1.2.bn3.weight \t torch.Size([256])\n",
      "layer1.2.bn3.bias \t torch.Size([256])\n",
      "layer1.2.bn3.running_mean \t torch.Size([256])\n",
      "layer1.2.bn3.running_var \t torch.Size([256])\n",
      "layer1.2.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer2.0.conv1.weight \t torch.Size([128, 256, 1, 1])\n",
      "layer2.0.bn1.weight \t torch.Size([128])\n",
      "layer2.0.bn1.bias \t torch.Size([128])\n",
      "layer2.0.bn1.running_mean \t torch.Size([128])\n",
      "layer2.0.bn1.running_var \t torch.Size([128])\n",
      "layer2.0.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer2.0.conv2.weight \t torch.Size([128, 128, 3, 3])\n",
      "layer2.0.bn2.weight \t torch.Size([128])\n",
      "layer2.0.bn2.bias \t torch.Size([128])\n",
      "layer2.0.bn2.running_mean \t torch.Size([128])\n",
      "layer2.0.bn2.running_var \t torch.Size([128])\n",
      "layer2.0.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer2.0.conv3.weight \t torch.Size([512, 128, 1, 1])\n",
      "layer2.0.bn3.weight \t torch.Size([512])\n",
      "layer2.0.bn3.bias \t torch.Size([512])\n",
      "layer2.0.bn3.running_mean \t torch.Size([512])\n",
      "layer2.0.bn3.running_var \t torch.Size([512])\n",
      "layer2.0.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer2.0.downsample.0.weight \t torch.Size([512, 256, 1, 1])\n",
      "layer2.0.downsample.1.weight \t torch.Size([512])\n",
      "layer2.0.downsample.1.bias \t torch.Size([512])\n",
      "layer2.0.downsample.1.running_mean \t torch.Size([512])\n",
      "layer2.0.downsample.1.running_var \t torch.Size([512])\n",
      "layer2.0.downsample.1.num_batches_tracked \t torch.Size([])\n",
      "layer2.1.conv1.weight \t torch.Size([128, 512, 1, 1])\n",
      "layer2.1.bn1.weight \t torch.Size([128])\n",
      "layer2.1.bn1.bias \t torch.Size([128])\n",
      "layer2.1.bn1.running_mean \t torch.Size([128])\n",
      "layer2.1.bn1.running_var \t torch.Size([128])\n",
      "layer2.1.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer2.1.conv2.weight \t torch.Size([128, 128, 3, 3])\n",
      "layer2.1.bn2.weight \t torch.Size([128])\n",
      "layer2.1.bn2.bias \t torch.Size([128])\n",
      "layer2.1.bn2.running_mean \t torch.Size([128])\n",
      "layer2.1.bn2.running_var \t torch.Size([128])\n",
      "layer2.1.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer2.1.conv3.weight \t torch.Size([512, 128, 1, 1])\n",
      "layer2.1.bn3.weight \t torch.Size([512])\n",
      "layer2.1.bn3.bias \t torch.Size([512])\n",
      "layer2.1.bn3.running_mean \t torch.Size([512])\n",
      "layer2.1.bn3.running_var \t torch.Size([512])\n",
      "layer2.1.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer2.2.conv1.weight \t torch.Size([128, 512, 1, 1])\n",
      "layer2.2.bn1.weight \t torch.Size([128])\n",
      "layer2.2.bn1.bias \t torch.Size([128])\n",
      "layer2.2.bn1.running_mean \t torch.Size([128])\n",
      "layer2.2.bn1.running_var \t torch.Size([128])\n",
      "layer2.2.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer2.2.conv2.weight \t torch.Size([128, 128, 3, 3])\n",
      "layer2.2.bn2.weight \t torch.Size([128])\n",
      "layer2.2.bn2.bias \t torch.Size([128])\n",
      "layer2.2.bn2.running_mean \t torch.Size([128])\n",
      "layer2.2.bn2.running_var \t torch.Size([128])\n",
      "layer2.2.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer2.2.conv3.weight \t torch.Size([512, 128, 1, 1])\n",
      "layer2.2.bn3.weight \t torch.Size([512])\n",
      "layer2.2.bn3.bias \t torch.Size([512])\n",
      "layer2.2.bn3.running_mean \t torch.Size([512])\n",
      "layer2.2.bn3.running_var \t torch.Size([512])\n",
      "layer2.2.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer2.3.conv1.weight \t torch.Size([128, 512, 1, 1])\n",
      "layer2.3.bn1.weight \t torch.Size([128])\n",
      "layer2.3.bn1.bias \t torch.Size([128])\n",
      "layer2.3.bn1.running_mean \t torch.Size([128])\n",
      "layer2.3.bn1.running_var \t torch.Size([128])\n",
      "layer2.3.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer2.3.conv2.weight \t torch.Size([128, 128, 3, 3])\n",
      "layer2.3.bn2.weight \t torch.Size([128])\n",
      "layer2.3.bn2.bias \t torch.Size([128])\n",
      "layer2.3.bn2.running_mean \t torch.Size([128])\n",
      "layer2.3.bn2.running_var \t torch.Size([128])\n",
      "layer2.3.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer2.3.conv3.weight \t torch.Size([512, 128, 1, 1])\n",
      "layer2.3.bn3.weight \t torch.Size([512])\n",
      "layer2.3.bn3.bias \t torch.Size([512])\n",
      "layer2.3.bn3.running_mean \t torch.Size([512])\n",
      "layer2.3.bn3.running_var \t torch.Size([512])\n",
      "layer2.3.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer3.0.conv1.weight \t torch.Size([256, 512, 1, 1])\n",
      "layer3.0.bn1.weight \t torch.Size([256])\n",
      "layer3.0.bn1.bias \t torch.Size([256])\n",
      "layer3.0.bn1.running_mean \t torch.Size([256])\n",
      "layer3.0.bn1.running_var \t torch.Size([256])\n",
      "layer3.0.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer3.0.conv2.weight \t torch.Size([256, 256, 3, 3])\n",
      "layer3.0.bn2.weight \t torch.Size([256])\n",
      "layer3.0.bn2.bias \t torch.Size([256])\n",
      "layer3.0.bn2.running_mean \t torch.Size([256])\n",
      "layer3.0.bn2.running_var \t torch.Size([256])\n",
      "layer3.0.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer3.0.conv3.weight \t torch.Size([1024, 256, 1, 1])\n",
      "layer3.0.bn3.weight \t torch.Size([1024])\n",
      "layer3.0.bn3.bias \t torch.Size([1024])\n",
      "layer3.0.bn3.running_mean \t torch.Size([1024])\n",
      "layer3.0.bn3.running_var \t torch.Size([1024])\n",
      "layer3.0.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer3.0.downsample.0.weight \t torch.Size([1024, 512, 1, 1])\n",
      "layer3.0.downsample.1.weight \t torch.Size([1024])\n",
      "layer3.0.downsample.1.bias \t torch.Size([1024])\n",
      "layer3.0.downsample.1.running_mean \t torch.Size([1024])\n",
      "layer3.0.downsample.1.running_var \t torch.Size([1024])\n",
      "layer3.0.downsample.1.num_batches_tracked \t torch.Size([])\n",
      "layer3.1.conv1.weight \t torch.Size([256, 1024, 1, 1])\n",
      "layer3.1.bn1.weight \t torch.Size([256])\n",
      "layer3.1.bn1.bias \t torch.Size([256])\n",
      "layer3.1.bn1.running_mean \t torch.Size([256])\n",
      "layer3.1.bn1.running_var \t torch.Size([256])\n",
      "layer3.1.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer3.1.conv2.weight \t torch.Size([256, 256, 3, 3])\n",
      "layer3.1.bn2.weight \t torch.Size([256])\n",
      "layer3.1.bn2.bias \t torch.Size([256])\n",
      "layer3.1.bn2.running_mean \t torch.Size([256])\n",
      "layer3.1.bn2.running_var \t torch.Size([256])\n",
      "layer3.1.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer3.1.conv3.weight \t torch.Size([1024, 256, 1, 1])\n",
      "layer3.1.bn3.weight \t torch.Size([1024])\n",
      "layer3.1.bn3.bias \t torch.Size([1024])\n",
      "layer3.1.bn3.running_mean \t torch.Size([1024])\n",
      "layer3.1.bn3.running_var \t torch.Size([1024])\n",
      "layer3.1.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer3.2.conv1.weight \t torch.Size([256, 1024, 1, 1])\n",
      "layer3.2.bn1.weight \t torch.Size([256])\n",
      "layer3.2.bn1.bias \t torch.Size([256])\n",
      "layer3.2.bn1.running_mean \t torch.Size([256])\n",
      "layer3.2.bn1.running_var \t torch.Size([256])\n",
      "layer3.2.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer3.2.conv2.weight \t torch.Size([256, 256, 3, 3])\n",
      "layer3.2.bn2.weight \t torch.Size([256])\n",
      "layer3.2.bn2.bias \t torch.Size([256])\n",
      "layer3.2.bn2.running_mean \t torch.Size([256])\n",
      "layer3.2.bn2.running_var \t torch.Size([256])\n",
      "layer3.2.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer3.2.conv3.weight \t torch.Size([1024, 256, 1, 1])\n",
      "layer3.2.bn3.weight \t torch.Size([1024])\n",
      "layer3.2.bn3.bias \t torch.Size([1024])\n",
      "layer3.2.bn3.running_mean \t torch.Size([1024])\n",
      "layer3.2.bn3.running_var \t torch.Size([1024])\n",
      "layer3.2.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer3.3.conv1.weight \t torch.Size([256, 1024, 1, 1])\n",
      "layer3.3.bn1.weight \t torch.Size([256])\n",
      "layer3.3.bn1.bias \t torch.Size([256])\n",
      "layer3.3.bn1.running_mean \t torch.Size([256])\n",
      "layer3.3.bn1.running_var \t torch.Size([256])\n",
      "layer3.3.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer3.3.conv2.weight \t torch.Size([256, 256, 3, 3])\n",
      "layer3.3.bn2.weight \t torch.Size([256])\n",
      "layer3.3.bn2.bias \t torch.Size([256])\n",
      "layer3.3.bn2.running_mean \t torch.Size([256])\n",
      "layer3.3.bn2.running_var \t torch.Size([256])\n",
      "layer3.3.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer3.3.conv3.weight \t torch.Size([1024, 256, 1, 1])\n",
      "layer3.3.bn3.weight \t torch.Size([1024])\n",
      "layer3.3.bn3.bias \t torch.Size([1024])\n",
      "layer3.3.bn3.running_mean \t torch.Size([1024])\n",
      "layer3.3.bn3.running_var \t torch.Size([1024])\n",
      "layer3.3.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer3.4.conv1.weight \t torch.Size([256, 1024, 1, 1])\n",
      "layer3.4.bn1.weight \t torch.Size([256])\n",
      "layer3.4.bn1.bias \t torch.Size([256])\n",
      "layer3.4.bn1.running_mean \t torch.Size([256])\n",
      "layer3.4.bn1.running_var \t torch.Size([256])\n",
      "layer3.4.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer3.4.conv2.weight \t torch.Size([256, 256, 3, 3])\n",
      "layer3.4.bn2.weight \t torch.Size([256])\n",
      "layer3.4.bn2.bias \t torch.Size([256])\n",
      "layer3.4.bn2.running_mean \t torch.Size([256])\n",
      "layer3.4.bn2.running_var \t torch.Size([256])\n",
      "layer3.4.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer3.4.conv3.weight \t torch.Size([1024, 256, 1, 1])\n",
      "layer3.4.bn3.weight \t torch.Size([1024])\n",
      "layer3.4.bn3.bias \t torch.Size([1024])\n",
      "layer3.4.bn3.running_mean \t torch.Size([1024])\n",
      "layer3.4.bn3.running_var \t torch.Size([1024])\n",
      "layer3.4.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer3.5.conv1.weight \t torch.Size([256, 1024, 1, 1])\n",
      "layer3.5.bn1.weight \t torch.Size([256])\n",
      "layer3.5.bn1.bias \t torch.Size([256])\n",
      "layer3.5.bn1.running_mean \t torch.Size([256])\n",
      "layer3.5.bn1.running_var \t torch.Size([256])\n",
      "layer3.5.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer3.5.conv2.weight \t torch.Size([256, 256, 3, 3])\n",
      "layer3.5.bn2.weight \t torch.Size([256])\n",
      "layer3.5.bn2.bias \t torch.Size([256])\n",
      "layer3.5.bn2.running_mean \t torch.Size([256])\n",
      "layer3.5.bn2.running_var \t torch.Size([256])\n",
      "layer3.5.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer3.5.conv3.weight \t torch.Size([1024, 256, 1, 1])\n",
      "layer3.5.bn3.weight \t torch.Size([1024])\n",
      "layer3.5.bn3.bias \t torch.Size([1024])\n",
      "layer3.5.bn3.running_mean \t torch.Size([1024])\n",
      "layer3.5.bn3.running_var \t torch.Size([1024])\n",
      "layer3.5.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer4.0.conv1.weight \t torch.Size([512, 1024, 1, 1])\n",
      "layer4.0.bn1.weight \t torch.Size([512])\n",
      "layer4.0.bn1.bias \t torch.Size([512])\n",
      "layer4.0.bn1.running_mean \t torch.Size([512])\n",
      "layer4.0.bn1.running_var \t torch.Size([512])\n",
      "layer4.0.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer4.0.conv2.weight \t torch.Size([512, 512, 3, 3])\n",
      "layer4.0.bn2.weight \t torch.Size([512])\n",
      "layer4.0.bn2.bias \t torch.Size([512])\n",
      "layer4.0.bn2.running_mean \t torch.Size([512])\n",
      "layer4.0.bn2.running_var \t torch.Size([512])\n",
      "layer4.0.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer4.0.conv3.weight \t torch.Size([2048, 512, 1, 1])\n",
      "layer4.0.bn3.weight \t torch.Size([2048])\n",
      "layer4.0.bn3.bias \t torch.Size([2048])\n",
      "layer4.0.bn3.running_mean \t torch.Size([2048])\n",
      "layer4.0.bn3.running_var \t torch.Size([2048])\n",
      "layer4.0.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer4.0.downsample.0.weight \t torch.Size([2048, 1024, 1, 1])\n",
      "layer4.0.downsample.1.weight \t torch.Size([2048])\n",
      "layer4.0.downsample.1.bias \t torch.Size([2048])\n",
      "layer4.0.downsample.1.running_mean \t torch.Size([2048])\n",
      "layer4.0.downsample.1.running_var \t torch.Size([2048])\n",
      "layer4.0.downsample.1.num_batches_tracked \t torch.Size([])\n",
      "layer4.1.conv1.weight \t torch.Size([512, 2048, 1, 1])\n",
      "layer4.1.bn1.weight \t torch.Size([512])\n",
      "layer4.1.bn1.bias \t torch.Size([512])\n",
      "layer4.1.bn1.running_mean \t torch.Size([512])\n",
      "layer4.1.bn1.running_var \t torch.Size([512])\n",
      "layer4.1.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer4.1.conv2.weight \t torch.Size([512, 512, 3, 3])\n",
      "layer4.1.bn2.weight \t torch.Size([512])\n",
      "layer4.1.bn2.bias \t torch.Size([512])\n",
      "layer4.1.bn2.running_mean \t torch.Size([512])\n",
      "layer4.1.bn2.running_var \t torch.Size([512])\n",
      "layer4.1.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer4.1.conv3.weight \t torch.Size([2048, 512, 1, 1])\n",
      "layer4.1.bn3.weight \t torch.Size([2048])\n",
      "layer4.1.bn3.bias \t torch.Size([2048])\n",
      "layer4.1.bn3.running_mean \t torch.Size([2048])\n",
      "layer4.1.bn3.running_var \t torch.Size([2048])\n",
      "layer4.1.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer4.2.conv1.weight \t torch.Size([512, 2048, 1, 1])\n",
      "layer4.2.bn1.weight \t torch.Size([512])\n",
      "layer4.2.bn1.bias \t torch.Size([512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer4.2.bn1.running_mean \t torch.Size([512])\n",
      "layer4.2.bn1.running_var \t torch.Size([512])\n",
      "layer4.2.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer4.2.conv2.weight \t torch.Size([512, 512, 3, 3])\n",
      "layer4.2.bn2.weight \t torch.Size([512])\n",
      "layer4.2.bn2.bias \t torch.Size([512])\n",
      "layer4.2.bn2.running_mean \t torch.Size([512])\n",
      "layer4.2.bn2.running_var \t torch.Size([512])\n",
      "layer4.2.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer4.2.conv3.weight \t torch.Size([2048, 512, 1, 1])\n",
      "layer4.2.bn3.weight \t torch.Size([2048])\n",
      "layer4.2.bn3.bias \t torch.Size([2048])\n",
      "layer4.2.bn3.running_mean \t torch.Size([2048])\n",
      "layer4.2.bn3.running_var \t torch.Size([2048])\n",
      "layer4.2.bn3.num_batches_tracked \t torch.Size([])\n",
      "fc.weight \t torch.Size([120, 2048])\n",
      "fc.bias \t torch.Size([120])\n"
     ]
    }
   ],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.001, 'params': [2990911745464, 2990911744424]}]\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validate Model\n",
    "\n",
    "def train_model(loader, model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    \n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    history  = [] \n",
    "    \n",
    "    dataset_sizes = {\n",
    "        'train': len(loader['train'].dataset),\n",
    "        'valid': len(loader['valid'].dataset)\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        for phase in ['train', 'valid']:\n",
    "            \n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "            \n",
    "            for inputs, labels, iids in loader[phase]:\n",
    "                if use_gpu:\n",
    "                    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs.data, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # statistic\n",
    "                running_loss += loss.item()\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            \n",
    "            data_size = dataset_sizes[phase]\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_epoch_loss = running_loss / data_size\n",
    "                train_epoch_acc  = running_corrects / data_size\n",
    "            else:\n",
    "                valid_epoch_loss = running_loss / data_size\n",
    "                valid_epoch_acc  = running_corrects / data_size\n",
    "\n",
    "            if phase == 'valid' and valid_epoch_acc > best_acc:\n",
    "                best_acc = valid_epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        history.append({\n",
    "            'train_acc' : train_epoch_acc.item(), \n",
    "            'train_loss': train_epoch_loss, \n",
    "            'valid_acc' : valid_epoch_acc.item(),\n",
    "            'valid_loss': valid_epoch_loss\n",
    "        })\n",
    "        \n",
    "        print('Epoch [{:3d}/{:3d}] train loss: {:.4f} acc: {:.4f}' \n",
    "              '\\n                valid loss: {:.4f} acc: {:.4f}'.format(\n",
    "                  epoch, num_epochs - 1,\n",
    "                  train_epoch_loss, train_epoch_acc, \n",
    "                  valid_epoch_loss, valid_epoch_acc))\n",
    "\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_acc, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  0/  1] train loss: 0.0582 acc: 0.8145\n",
      "                valid loss: 0.0496 acc: 0.7961\n",
      "Epoch [  1/  1] train loss: 0.0530 acc: 0.8201\n",
      "                valid loss: 0.0468 acc: 0.8039\n",
      "Best val Acc: 0.803912\n",
      "Training time:   5.550044 minutes\n"
     ]
    }
   ],
   "source": [
    "NumEpochs = 2\n",
    "start_time = time.time()\n",
    "\n",
    "best_model, best_acc, history = train_model(\n",
    "    dataLoader, model, criterion, optimizer, exp_lr_scheduler, NumEpochs\n",
    ")\n",
    "    \n",
    "print('Training time: {:10f} minutes'.format((time.time()-start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"train_acc\": 0.814479649066925, \"train_loss\": 0.0582491326072593, \"valid_acc\": 0.7960880398750305, \"valid_loss\": 0.04964077915713956}, {\"train_acc\": 0.8201051354408264, \"train_loss\": 0.052958092071964266, \"valid_acc\": 0.8039119839668274, \"valid_loss\": 0.046761533246355125}]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(json.dumps(history))\n",
    "\n",
    "train_acc  = []\n",
    "train_loss = []\n",
    "valid_acc  = []\n",
    "valid_loss = []\n",
    "\n",
    "for i in range(len(history)):\n",
    "    train_acc.append(history[i]['train_acc'])\n",
    "    train_loss.append(history[i]['train_loss'])\n",
    "\n",
    "    valid_acc.append(history[i]['valid_acc'])\n",
    "    valid_loss.append(history[i]['valid_loss'])\n",
    "        \n",
    "def plot_lines(y1, y2, label=None, ax=None):\n",
    "    epochs = len(history)\n",
    "    x = np.linspace(0, epochs, num=epochs)\n",
    "    ax.plot(x, y1, label=\"train\")\n",
    "    ax.plot(x, y2, label=\"valid\")\n",
    "    ax.set_title('training v.s. validate')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel(label)\n",
    "    \n",
    "    \n",
    "# 1. Plot in same line, this would work\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "plot_lines(train_acc, train_loss, 'train', ax1)\n",
    "\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "plot_lines(valid_acc, valid_loss, 'valid', ax2)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "currDT = datetime.now()\n",
    "currStr = currDT.strftime(\"%Y%m%d-%H%M\")\n",
    "\n",
    "acc_str = int(best_acc * 100)\n",
    "fname_best_model = 'resnet50_{}_acc{}.pth'.format(currStr, acc_str)\n",
    "\n",
    "best_model_wts = best_model.state_dict()\n",
    "\n",
    "OutPath = Params['OutPath']\n",
    "best_model_out = join(OutPath, fname_best_model)\n",
    "\n",
    "torch.save(best_model_wts, best_model_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"DataPath\": \"D:\\\\GitWork\\\\dog_breed\\\\data\",\n",
      "    \"OutPath\": \"D:\\\\GitWork\\\\dog_breed\\\\output\",\n",
      "    \"ProcPath\": \"D:\\\\GitWork\\\\dog_breed\\\\processed\",\n",
      "    \"PreTrainPath\": \"D:\\\\GitWork\\\\dog_breed\\\\pretrained\",\n",
      "    \"PreTrainFile\": \"resnet50_20200923-1604_acc79.pth\",\n",
      "    \"LoadPreModel\": true,\n",
      "    \"TestPath\": \"D:\\\\GitWork\\\\dog_breed\\\\data\\\\test\",\n",
      "    \"TrainPath\": \"D:\\\\GitWork\\\\dog_breed\\\\data\\\\train\",\n",
      "    \"CsvLabel\": \"labels.csv\",\n",
      "    \"BatchSize\": 16,\n",
      "    \"FracForTrain\": 0.8\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Save parameters to json file\n",
    "\n",
    "fname = 'Params_{}.json'.format(currStr)\n",
    "f_abspath = join(OutPath, fname)\n",
    "\n",
    "json_str = json.dumps(Params, indent=4)\n",
    "print(json_str)\n",
    "\n",
    "with open(f_abspath, 'w') as fout:\n",
    "    fout.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"scottish_deerhound\": 0,\n",
      "    \"maltese_dog\": 1,\n",
      "    \"afghan_hound\": 2,\n",
      "    \"entlebucher\": 3,\n",
      "    \"bernese_mountain_dog\": 4,\n",
      "    \"shih-tzu\": 5,\n",
      "    \"great_pyrenees\": 6,\n",
      "    \"pomeranian\": 7,\n",
      "    \"basenji\": 8,\n",
      "    \"samoyed\": 9,\n",
      "    \"airedale\": 10,\n",
      "    \"tibetan_terrier\": 11,\n",
      "    \"leonberg\": 12,\n",
      "    \"cairn\": 13,\n",
      "    \"beagle\": 14,\n",
      "    \"japanese_spaniel\": 15,\n",
      "    \"australian_terrier\": 16,\n",
      "    \"blenheim_spaniel\": 17,\n",
      "    \"miniature_pinscher\": 18,\n",
      "    \"irish_wolfhound\": 19,\n",
      "    \"lakeland_terrier\": 20,\n",
      "    \"saluki\": 21,\n",
      "    \"papillon\": 22,\n",
      "    \"whippet\": 23,\n",
      "    \"siberian_husky\": 24,\n",
      "    \"norwegian_elkhound\": 25,\n",
      "    \"pug\": 26,\n",
      "    \"chow\": 27,\n",
      "    \"italian_greyhound\": 28,\n",
      "    \"pembroke\": 29,\n",
      "    \"ibizan_hound\": 30,\n",
      "    \"border_terrier\": 31,\n",
      "    \"newfoundland\": 32,\n",
      "    \"lhasa\": 33,\n",
      "    \"silky_terrier\": 34,\n",
      "    \"bedlington_terrier\": 35,\n",
      "    \"dandie_dinmont\": 36,\n",
      "    \"irish_setter\": 37,\n",
      "    \"sealyham_terrier\": 38,\n",
      "    \"rhodesian_ridgeback\": 39,\n",
      "    \"old_english_sheepdog\": 40,\n",
      "    \"collie\": 41,\n",
      "    \"boston_bull\": 42,\n",
      "    \"english_foxhound\": 43,\n",
      "    \"bouvier_des_flandres\": 44,\n",
      "    \"african_hunting_dog\": 45,\n",
      "    \"schipperke\": 46,\n",
      "    \"kelpie\": 47,\n",
      "    \"weimaraner\": 48,\n",
      "    \"bloodhound\": 49,\n",
      "    \"bluetick\": 50,\n",
      "    \"saint_bernard\": 51,\n",
      "    \"labrador_retriever\": 52,\n",
      "    \"chesapeake_bay_retriever\": 53,\n",
      "    \"norfolk_terrier\": 54,\n",
      "    \"english_setter\": 55,\n",
      "    \"wire-haired_fox_terrier\": 56,\n",
      "    \"kerry_blue_terrier\": 57,\n",
      "    \"scotch_terrier\": 58,\n",
      "    \"yorkshire_terrier\": 59,\n",
      "    \"groenendael\": 60,\n",
      "    \"greater_swiss_mountain_dog\": 61,\n",
      "    \"irish_terrier\": 62,\n",
      "    \"basset\": 63,\n",
      "    \"keeshond\": 64,\n",
      "    \"west_highland_white_terrier\": 65,\n",
      "    \"gordon_setter\": 66,\n",
      "    \"malamute\": 67,\n",
      "    \"affenpinscher\": 68,\n",
      "    \"toy_poodle\": 69,\n",
      "    \"clumber\": 70,\n",
      "    \"mexican_hairless\": 71,\n",
      "    \"dingo\": 72,\n",
      "    \"standard_poodle\": 73,\n",
      "    \"miniature_poodle\": 74,\n",
      "    \"staffordshire_bullterrier\": 75,\n",
      "    \"welsh_springer_spaniel\": 76,\n",
      "    \"toy_terrier\": 77,\n",
      "    \"sussex_spaniel\": 78,\n",
      "    \"norwich_terrier\": 79,\n",
      "    \"appenzeller\": 80,\n",
      "    \"irish_water_spaniel\": 81,\n",
      "    \"miniature_schnauzer\": 82,\n",
      "    \"black-and-tan_coonhound\": 83,\n",
      "    \"cardigan\": 84,\n",
      "    \"dhole\": 85,\n",
      "    \"shetland_sheepdog\": 86,\n",
      "    \"rottweiler\": 87,\n",
      "    \"english_springer\": 88,\n",
      "    \"great_dane\": 89,\n",
      "    \"german_short-haired_pointer\": 90,\n",
      "    \"boxer\": 91,\n",
      "    \"bull_mastiff\": 92,\n",
      "    \"borzoi\": 93,\n",
      "    \"pekinese\": 94,\n",
      "    \"cocker_spaniel\": 95,\n",
      "    \"american_staffordshire_terrier\": 96,\n",
      "    \"doberman\": 97,\n",
      "    \"brittany_spaniel\": 98,\n",
      "    \"malinois\": 99,\n",
      "    \"standard_schnauzer\": 100,\n",
      "    \"flat-coated_retriever\": 101,\n",
      "    \"redbone\": 102,\n",
      "    \"border_collie\": 103,\n",
      "    \"curly-coated_retriever\": 104,\n",
      "    \"kuvasz\": 105,\n",
      "    \"chihuahua\": 106,\n",
      "    \"soft-coated_wheaten_terrier\": 107,\n",
      "    \"french_bulldog\": 108,\n",
      "    \"vizsla\": 109,\n",
      "    \"tibetan_mastiff\": 110,\n",
      "    \"german_shepherd\": 111,\n",
      "    \"giant_schnauzer\": 112,\n",
      "    \"walker_hound\": 113,\n",
      "    \"otterhound\": 114,\n",
      "    \"golden_retriever\": 115,\n",
      "    \"brabancon_griffon\": 116,\n",
      "    \"komondor\": 117,\n",
      "    \"briard\": 118,\n",
      "    \"eskimo_dog\": 119\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Save breed dict to json file\n",
    "fname = 'BreedDict_{}.json'.format(currStr)\n",
    "f_abspath = join(OutPath, fname)\n",
    "\n",
    "json_str = json.dumps(dict_bid_fw, indent=4)\n",
    "print(json_str)\n",
    "\n",
    "with open(f_abspath, 'w') as fout:\n",
    "    fout.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
